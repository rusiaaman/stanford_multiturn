{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/miniconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/usr/lib/miniconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/miniconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [\"what is <> doing?\",\"what is being done by <>?\",\"<> is upto what?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"john\",\"aman\",\"aparna\",\"dog\",\"amit\",\"ketan\"]\n",
    "actions = [\"dancing\",\"playing\",\"singing\",\"skating\",\"riding\",\"climbing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_utter(n,act_name):\n",
    "    opts = [\n",
    "        n+' is '+act_name,\n",
    "        act_name,\n",
    "        \"I think \"+n+' is '+act_name,\n",
    "        \"I guess\"+n+' is '+act_name,\n",
    "        n+' is '+act_name+\" I believe.\",\n",
    "        n+' is '+act_name+\" is my guess\",\n",
    "    ]\n",
    "    return opts[np.random.randint(len(opts))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "X_name = []\n",
    "Y=[]\n",
    "N=[]\n",
    "def gen_sent(inputs,names,actions):\n",
    "    for n in names:\n",
    "        for ii in range(len(inputs)*100):\n",
    "            i = inputs[ii%len(inputs)]\n",
    "            X.append(re.sub(r'<>',n,i))\n",
    "            X_name.append(n)\n",
    "            num=np.random.randint(len(actions)*100)\n",
    "            Y.append(sample_utter(n,actions[num%len(actions)]))\n",
    "            N.append(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['john is riding is my guess',\n",
       " 'john is skating',\n",
       " 'john is playing',\n",
       " 'I guessjohn is skating',\n",
       " 'skating']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_sent(inputs,names,actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer,one_hot\n",
    "from keras.models import Model\n",
    "from keras.layers import Input,Dense\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.fit_on_texts(X)\n",
    "t.fit_on_texts(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.index_word = {i:w for w,i in t.word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_len=len(t.word_index.keys())+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DB_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelling the db\n",
    "m_in = Input(shape=(vocab_len,))\n",
    "m = Dense(100,activation='relu')(m_in)\n",
    "m = Dense(vocab_len,activation='sigmoid')(m)\n",
    "db_model = Model(inputs=[m_in],outputs=[m])\n",
    "db_model.compile(loss='binary_crossentropy',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(w, t = 1.0):\n",
    "    e = np.exp(np.array(w) / t)\n",
    "    dist = e / np.sum(e)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9835306461587442"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(softmax(np.random.normal(size=vocab_len,loc=100,scale=5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "db_X = []\n",
    "db_Y = []\n",
    "for _ in range(1000):\n",
    "    vec = softmax(np.random.normal(size=vocab_len,loc=100,scale=5))\n",
    "    v= t.index_word[np.argmax(vec)] if np.max(vec)>0.5 and np.argmax(vec)!=0 else ''\n",
    "    for _ in range(100):\n",
    "        db_X.append(vec)\n",
    "        if v not in names:\n",
    "            db_Y.append(np.array([0  for ii in range(vocab_len)]))\n",
    "            continue\n",
    "        num=np.random.randint(len(actions))\n",
    "        ix = t.word_index[actions[num]]\n",
    "        db_Y.append(np.array(to_categorical([ix],num_classes=vocab_len))[0])\n",
    "dist=np.random.permutation(len(db_X))\n",
    "db_Y = np.array(db_Y)[dist]\n",
    "db_X = np.array(db_X)[dist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def db_model_fit(epochs):\n",
    "    db_model.fit(np.array(db_X),np.array(db_Y),epochs=epochs,validation_split=0.2,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/2\n",
      "80000/80000 [==============================] - 6s 80us/step - loss: 0.0577 - val_loss: 0.0169\n",
      "Epoch 2/2\n",
      "80000/80000 [==============================] - 5s 58us/step - loss: 0.0164 - val_loss: 0.0162\n"
     ]
    }
   ],
   "source": [
    "db_model_fit(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing db_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_categorical(t.texts_to_sequences([\"Aman what doing\"]),num_classes=vocab_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=db_model.predict(to_categorical(t.texts_to_sequences([\"Aman what doing\"]),num_classes=vocab_len)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  2,  5, 10, 24, 26,  4, 29, 16,  1, 30, 28,  9, 15,  3, 13,\n",
       "         8, 12,  6, 11,  7, 23, 27, 14, 25, 19, 18, 21, 22, 20, 17],\n",
       "       [ 4,  8, 13,  0,  7, 29, 16, 11, 15,  1, 28,  5, 26,  2,  6, 10,\n",
       "         3, 25, 27,  9, 30, 24, 23, 12, 14, 19, 17, 21, 18, 20, 22],\n",
       "       [13,  4,  8, 28,  1,  5, 25, 29, 26,  0, 10,  7, 30, 15, 16,  3,\n",
       "         6, 11, 24,  9, 27,  2, 12, 14, 23, 21, 19, 18, 17, 22, 20]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.argsort(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 28, 27, 26, 25, 24, 23, 16, 29, 14, 13, 12, 15, 10,  1,  2,  3,\n",
       "        4,  5,  6, 11, 30,  7,  8,  9, 18, 22, 17, 19, 21, 20])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(np.sum(db_Y,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('null', 0.00020549457),\n",
       "  ('what', 0.00022035681),\n",
       "  ('being', 0.00025001532),\n",
       "  ('aparna', 0.00027015933),\n",
       "  ('guess', 0.00027812005),\n",
       "  ('guessamit', 0.0002902962),\n",
       "  ('doing', 0.0003047225),\n",
       "  ('guessdog', 0.00030590312),\n",
       "  ('believe', 0.0003135274),\n",
       "  ('is', 0.0003214629),\n",
       "  ('guessaparna', 0.00032192966),\n",
       "  ('guessketan', 0.00032545443),\n",
       "  ('dog', 0.00032789205),\n",
       "  ('think', 0.00034241384),\n",
       "  ('i', 0.0003477852),\n",
       "  ('aman', 0.00035251956),\n",
       "  ('upto', 0.0003548911),\n",
       "  ('amit', 0.0003607396),\n",
       "  ('done', 0.00036165604),\n",
       "  ('john', 0.00037062744),\n",
       "  ('by', 0.00037775622),\n",
       "  ('my', 0.00040202026),\n",
       "  ('guessjohn', 0.00040648843),\n",
       "  ('ketan', 0.00043073343),\n",
       "  ('guessaman', 0.0004505105),\n",
       "  ('climbing', 0.1547346),\n",
       "  ('skating', 0.18767904),\n",
       "  ('riding', 0.18811932),\n",
       "  ('dancing', 0.18911086),\n",
       "  ('singing', 0.19436792),\n",
       "  ('playing', 0.20278767)],\n",
       " [('doing', 1.693764e-05),\n",
       "  ('upto', 1.9104762e-05),\n",
       "  ('aman', 1.9766618e-05),\n",
       "  ('null', 2.0760584e-05),\n",
       "  ('by', 2.3600442e-05),\n",
       "  ('guessdog', 2.398798e-05),\n",
       "  ('believe', 2.4754048e-05),\n",
       "  ('john', 2.6096275e-05),\n",
       "  ('think', 2.6365007e-05),\n",
       "  ('is', 2.704559e-05),\n",
       "  ('guessketan', 2.7817865e-05),\n",
       "  ('being', 2.8597655e-05),\n",
       "  ('guessamit', 2.9096229e-05),\n",
       "  ('what', 3.1259216e-05),\n",
       "  ('done', 3.189911e-05),\n",
       "  ('aparna', 3.287139e-05),\n",
       "  ('i', 3.307799e-05),\n",
       "  ('guessaman', 3.4110555e-05),\n",
       "  ('guessjohn', 3.5459812e-05),\n",
       "  ('dog', 3.552053e-05),\n",
       "  ('guessaparna', 3.598109e-05),\n",
       "  ('guess', 3.7966434e-05),\n",
       "  ('my', 3.797726e-05),\n",
       "  ('amit', 3.877808e-05),\n",
       "  ('ketan', 4.0322684e-05),\n",
       "  ('climbing', 0.00028577395),\n",
       "  ('playing', 0.00030077458),\n",
       "  ('riding', 0.00030308173),\n",
       "  ('skating', 0.00031103485),\n",
       "  ('singing', 0.00034398996),\n",
       "  ('dancing', 0.00039212365)],\n",
       " [('aman', 1.7839711e-05),\n",
       "  ('doing', 1.8343891e-05),\n",
       "  ('upto', 1.8922316e-05),\n",
       "  ('guessketan', 2.1599499e-05),\n",
       "  ('is', 2.2860611e-05),\n",
       "  ('being', 2.3781431e-05),\n",
       "  ('guessaman', 2.4269322e-05),\n",
       "  ('guessdog', 2.5027948e-05),\n",
       "  ('guessamit', 2.5542144e-05),\n",
       "  ('null', 2.5545261e-05),\n",
       "  ('aparna', 2.5694422e-05),\n",
       "  ('by', 2.5792351e-05),\n",
       "  ('guessaparna', 2.7403557e-05),\n",
       "  ('think', 2.7610791e-05),\n",
       "  ('believe', 2.8119499e-05),\n",
       "  ('i', 2.9127099e-05),\n",
       "  ('done', 2.9593504e-05),\n",
       "  ('john', 2.9885992e-05),\n",
       "  ('guess', 3.2214415e-05),\n",
       "  ('dog', 3.335796e-05),\n",
       "  ('guessjohn', 3.3376607e-05),\n",
       "  ('what', 3.3676504e-05),\n",
       "  ('amit', 3.5633173e-05),\n",
       "  ('ketan', 3.9031147e-05),\n",
       "  ('my', 4.070789e-05),\n",
       "  ('riding', 0.00044189696),\n",
       "  ('climbing', 0.0004627961),\n",
       "  ('skating', 0.0005180479),\n",
       "  ('playing', 0.0005706847),\n",
       "  ('dancing', 0.0005853924),\n",
       "  ('singing', 0.00070374)]]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[(t.index_word[i],_j[i]) if i!=0 else ('null',_j[i]) for i in j] for j,_j in zip(y.argsort(axis=-1),y) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=db_model.predict(np.array([[0,0,0,0.9]+[0]*16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('what', 0.00026142027),\n",
       "  ('amit', 0.00028668376),\n",
       "  ('dog', 0.00030894805),\n",
       "  ('aman', 0.00031707078),\n",
       "  ('done', 0.00032131217),\n",
       "  ('by', 0.0003309926),\n",
       "  ('is', 0.00035546705),\n",
       "  ('john', 0.00036274322),\n",
       "  ('ketan', 0.00036345888),\n",
       "  ('being', 0.0003705994),\n",
       "  ('doing', 0.00040941368),\n",
       "  ('upto', 0.0004402966),\n",
       "  ('aparna', 0.0004516661),\n",
       "  ('null', 0.00045891947),\n",
       "  ('skating', 0.17328088),\n",
       "  ('climbing', 0.17810948),\n",
       "  ('dancing', 0.18361813),\n",
       "  ('riding', 0.18771142),\n",
       "  ('playing', 0.18953821),\n",
       "  ('singing', 0.19822973)]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[(t.index_word[i],_j[i]) if i!=0 else ('null',_j[i]) for i in j] for j,_j in zip(y.argsort(axis=-1),y) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.engine.network import Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "frozen_db_model = Network(\n",
    "    m_in,\n",
    "    m,\n",
    "    name='frozen_db_model'\n",
    ")\n",
    "frozen_db_model.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input((10,vocab_len))\n",
    "out = LSTM(50)(inp)\n",
    "out = Dense(vocab_len,activation='softmax')(out)\n",
    "model_rnn=Model(inputs=[inp],outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "out = frozen_db_model(model_rnn.output)\n",
    "model = Model(inputs=[model_rnn.input],outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_in=to_categorical(pad_sequences(t.texts_to_sequences(X),maxlen=10),num_classes=vocab_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_in = to_categorical([t.word_index[actions[n%len(actions)]] for n in N],num_classes=vocab_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis\n",
    "For model_rnn we feed in sentences, it should output the names. And the names when queried against the database should give the correct result. \n",
    "\n",
    "To train the model_rnn, we use db_model and plug it in to get the final output. The idea is that db_model models the probability of the db to return the corresponding result given the output of model_rnn.\n",
    "\n",
    "Hypothesis1: However since it only returns the probability and not the exact values, the training won't be possible. AS the model wouldn't know ever which value to predict for sure. And the association of the model_rnn output with the required final output wouldn't be complete.\n",
    "\n",
    "\n",
    "Hypothesis2: If we train the db_model with the event id, such that for particular event id whatever the output was, it remembers with high accuracy. Then while training, event id could be an input for corresponding dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii=866\n",
    "X[ii:ii+1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = np.random.permutation(len(X_in))\n",
    "X_inr = X_in[dist]\n",
    "Y_inr = Y_in[dist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1440 samples, validate on 360 samples\n",
      "Epoch 1/20\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.4789 - acc: 0.9500 - val_loss: 0.4608 - val_acc: 0.9500\n",
      "Epoch 2/20\n",
      "1440/1440 [==============================] - 1s 734us/step - loss: 0.4575 - acc: 0.9500 - val_loss: 0.4556 - val_acc: 0.9500\n",
      "Epoch 3/20\n",
      "1440/1440 [==============================] - 1s 748us/step - loss: 0.4535 - acc: 0.9500 - val_loss: 0.4504 - val_acc: 0.9500\n",
      "Epoch 4/20\n",
      "1440/1440 [==============================] - 1s 752us/step - loss: 0.4480 - acc: 0.9500 - val_loss: 0.4465 - val_acc: 0.9500\n",
      "Epoch 5/20\n",
      "1440/1440 [==============================] - 1s 799us/step - loss: 0.4467 - acc: 0.9500 - val_loss: 0.4462 - val_acc: 0.9500\n",
      "Epoch 6/20\n",
      "1440/1440 [==============================] - 1s 770us/step - loss: 0.4467 - acc: 0.9500 - val_loss: 0.4462 - val_acc: 0.9500\n",
      "Epoch 7/20\n",
      "1440/1440 [==============================] - 1s 768us/step - loss: 0.4466 - acc: 0.9500 - val_loss: 0.4461 - val_acc: 0.9500\n",
      "Epoch 8/20\n",
      "1440/1440 [==============================] - 1s 798us/step - loss: 0.4466 - acc: 0.9500 - val_loss: 0.4461 - val_acc: 0.9500\n",
      "Epoch 9/20\n",
      "1440/1440 [==============================] - 1s 823us/step - loss: 0.4466 - acc: 0.9500 - val_loss: 0.4461 - val_acc: 0.9500\n",
      "Epoch 10/20\n",
      "1440/1440 [==============================] - 1s 778us/step - loss: 0.4466 - acc: 0.9500 - val_loss: 0.4461 - val_acc: 0.9500\n",
      "Epoch 11/20\n",
      "1440/1440 [==============================] - 1s 863us/step - loss: 0.4466 - acc: 0.9500 - val_loss: 0.4461 - val_acc: 0.9500\n",
      "Epoch 12/20\n",
      "1440/1440 [==============================] - 1s 772us/step - loss: 0.4466 - acc: 0.9500 - val_loss: 0.4461 - val_acc: 0.9500\n",
      "Epoch 13/20\n",
      "1440/1440 [==============================] - 1s 760us/step - loss: 0.4465 - acc: 0.9500 - val_loss: 0.4461 - val_acc: 0.9500\n",
      "Epoch 14/20\n",
      "1440/1440 [==============================] - 1s 762us/step - loss: 0.4465 - acc: 0.9500 - val_loss: 0.4461 - val_acc: 0.9500\n",
      "Epoch 15/20\n",
      "1440/1440 [==============================] - 1s 771us/step - loss: 0.4465 - acc: 0.9500 - val_loss: 0.4461 - val_acc: 0.9500\n",
      "Epoch 16/20\n",
      "1440/1440 [==============================] - 1s 739us/step - loss: 0.4465 - acc: 0.9500 - val_loss: 0.4461 - val_acc: 0.9500\n",
      "Epoch 17/20\n",
      "1440/1440 [==============================] - 1s 742us/step - loss: 0.4465 - acc: 0.9500 - val_loss: 0.4461 - val_acc: 0.9500\n",
      "Epoch 18/20\n",
      "1440/1440 [==============================] - 1s 753us/step - loss: 0.4465 - acc: 0.9500 - val_loss: 0.4461 - val_acc: 0.9500\n",
      "Epoch 19/20\n",
      "1440/1440 [==============================] - 1s 749us/step - loss: 0.4465 - acc: 0.9500 - val_loss: 0.4461 - val_acc: 0.9500\n",
      "Epoch 20/20\n",
      "1440/1440 [==============================] - 1s 748us/step - loss: 0.4465 - acc: 0.9500 - val_loss: 0.4461 - val_acc: 0.9500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8d30246ac8>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.fit(X_inr,Y_inr,epochs=20,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing model rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what is being done by amit?']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ii=1222\n",
    "X[ii:ii+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1.25020798e-02, 3.68301034e-01, 5.46059513e-04, 1.66156344e-04,\n",
       "         7.81369527e-05, 3.28235074e-05, 4.48085302e-05, 3.89642737e-05,\n",
       "         4.80694143e-05, 6.71076775e-02, 3.56861092e-02, 3.08005866e-02,\n",
       "         1.11210831e-01, 1.25071099e-02, 3.58961403e-01, 1.03968167e-04,\n",
       "         1.27062449e-04, 8.68929346e-05, 2.02584779e-04, 2.89392425e-04,\n",
       "         9.37774093e-05, 2.70387769e-04, 7.99273912e-05, 6.83660401e-05,\n",
       "         1.07351771e-04, 4.53218963e-05, 4.72883075e-05, 2.08147540e-04,\n",
       "         5.35969339e-05, 6.72595415e-05, 1.16775205e-04]], dtype=float32),\n",
       " array([[7.68936734e-05, 9.30753522e-05, 8.32222722e-05, 9.60318794e-05,\n",
       "         8.77991333e-05, 1.16250994e-04, 7.89057958e-05, 8.03349903e-05,\n",
       "         9.11206516e-05, 8.43610323e-05, 1.08341628e-04, 7.03377300e-05,\n",
       "         8.44032766e-05, 1.22309692e-04, 1.03045117e-04, 1.69003740e-01,\n",
       "         1.40482083e-01, 9.70071123e-05, 1.61266521e-01, 9.93263820e-05,\n",
       "         9.66861044e-05, 1.50057688e-01, 1.33252531e-01, 7.88616453e-05,\n",
       "         1.55097306e-01, 8.04332594e-05, 8.48458149e-05, 9.39960883e-05,\n",
       "         1.02785045e-04, 9.71622721e-05, 1.05606858e-04]], dtype=float32)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=model_rnn.predict(X_in[ii:ii+1])\n",
    "model.predict(X_in[ii:ii+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.25020798e-02, 3.68301034e-01, 5.46059513e-04, 1.66156344e-04,\n",
       "        7.81369527e-05, 3.28235074e-05, 4.48085302e-05, 3.89642737e-05,\n",
       "        4.80694143e-05, 6.71076775e-02, 3.56861092e-02, 3.08005866e-02,\n",
       "        1.11210831e-01, 1.25071099e-02, 3.58961403e-01, 1.03968167e-04,\n",
       "        1.27062449e-04, 8.68929346e-05, 2.02584779e-04, 2.89392425e-04,\n",
       "        9.37774093e-05, 2.70387769e-04, 7.99273912e-05, 6.83660401e-05,\n",
       "        1.07351771e-04, 4.53218963e-05, 4.72883075e-05, 2.08147540e-04,\n",
       "        5.35969339e-05, 6.72595415e-05, 1.16775205e-04]], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'is',\n",
       " 2: 'what',\n",
       " 3: 'i',\n",
       " 4: 'doing',\n",
       " 5: 'being',\n",
       " 6: 'done',\n",
       " 7: 'by',\n",
       " 8: 'upto',\n",
       " 9: 'dog',\n",
       " 10: 'aparna',\n",
       " 11: 'john',\n",
       " 12: 'amit',\n",
       " 13: 'aman',\n",
       " 14: 'ketan',\n",
       " 15: 'think',\n",
       " 16: 'believe',\n",
       " 17: 'playing',\n",
       " 18: 'skating',\n",
       " 19: 'climbing',\n",
       " 20: 'singing',\n",
       " 21: 'riding',\n",
       " 22: 'dancing',\n",
       " 23: 'my',\n",
       " 24: 'guess',\n",
       " 25: 'guessaman',\n",
       " 26: 'guessamit',\n",
       " 27: 'guessjohn',\n",
       " 28: 'guessketan',\n",
       " 29: 'guessdog',\n",
       " 30: 'guessaparna'}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.0457224e-07, 1.1879730e-06, 1.0322865e-06, 1.2272013e-06,\n",
       "        7.3836287e-07, 6.8454915e-07, 1.5342617e-06, 1.1223832e-06,\n",
       "        6.7522473e-07, 1.5305002e-06, 1.0025216e-06, 7.4134601e-07,\n",
       "        1.0227470e-06, 7.7326280e-07, 1.3494027e-06, 1.0170628e-06,\n",
       "        9.9952877e-07, 5.6951995e-07, 4.1391286e-07, 6.3639453e-07,\n",
       "        3.8267402e-07, 5.9659351e-07, 5.7074391e-07, 1.3664762e-06,\n",
       "        1.3437266e-06, 9.0083932e-07, 1.2790896e-06, 1.3683775e-06,\n",
       "        1.3068997e-06, 9.4555094e-07, 1.2350961e-06]], dtype=float32)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_model.predict(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('is', 0.9997547),\n",
       " ('what', 0.00024442154),\n",
       " '',\n",
       " ('amit', 7.9605165e-08),\n",
       " ('dog', 6.358188e-08),\n",
       " ('john', 4.825296e-08),\n",
       " ('ketan', 3.139922e-08),\n",
       " ('aman', 2.9350415e-08),\n",
       " ('aparna', 2.6653815e-08),\n",
       " ('doing', 1.5053446e-08),\n",
       " ('done', 1.4722667e-08),\n",
       " ('upto', 1.279906e-08),\n",
       " ('being', 1.1407889e-08),\n",
       " ('guessaman', 9.183436e-09),\n",
       " ('by', 7.98632e-09),\n",
       " ('guessjohn', 7.702711e-09),\n",
       " ('guessketan', 7.2927953e-09),\n",
       " ('singing', 6.979357e-09),\n",
       " ('guess', 6.9270514e-09),\n",
       " ('guessdog', 6.1020584e-09),\n",
       " ('guessamit', 5.9828813e-09),\n",
       " ('my', 5.959431e-09),\n",
       " ('riding', 5.947905e-09),\n",
       " ('guessaparna', 5.6761262e-09),\n",
       " ('skating', 5.425327e-09),\n",
       " ('think', 5.19223e-09),\n",
       " ('dancing', 4.9146207e-09),\n",
       " ('believe', 3.632069e-09),\n",
       " ('climbing', 3.5582064e-09),\n",
       " ('i', 2.7873015e-09),\n",
       " ('playing', 2.6991402e-09)]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(t.index_word[i],y[0][i]) if i!=0 else '' for i in y.argsort(axis=-1)[0][-1::-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_in[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[to_categorical(t.word_index['skating'],num_classes=vocab_len)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.9607539e-06, 2.3289008e-06, 3.0498397e-06, 2.5500003e-06,\n",
       "        1.5545529e-06, 2.0252571e-06, 3.7756481e-06, 2.2511813e-06,\n",
       "        1.6099882e-06, 3.5145358e-06, 2.6573953e-06, 2.8243073e-06,\n",
       "        3.2971404e-06, 2.0790701e-06, 3.3225817e-06, 1.8950619e-06,\n",
       "        2.3109028e-06, 4.1045319e-06, 6.2974168e-06, 6.3568150e-06,\n",
       "        6.2556492e-06, 5.8926685e-06, 3.6681006e-06, 3.0840336e-06,\n",
       "        3.2481753e-06, 2.6144455e-06, 1.9214585e-06, 3.1966460e-06,\n",
       "        2.8269239e-06, 1.8827100e-06, 3.0188132e-06]], dtype=float32)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_model.predict(np.array([to_categorical(t.word_index['skating'],num_classes=vocab_len)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This validates our hypothesis as mode collapse happens quickly, and there is no gradient flow. \n",
    "Hypothesis 1.5: If we also train db_model together for the output of the model_rnn, it might work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_db_output(X,X_name,Y_true):\n",
    "    pred = np.max(X,axis=-1)\n",
    "    result = []\n",
    "    for i in range(len(X)):\n",
    "        p = pred[i]\n",
    "        if p<0.5:\n",
    "            result.append( np.zeros(vocab_len))\n",
    "            continue\n",
    "        v = np.argmax(X[i])\n",
    "        if v == t.word_index[X_name[i]]:\n",
    "            result.append(Y_true[i])\n",
    "        else:\n",
    "            if v in names:\n",
    "                result.append(to_categorical(np.random.randint(len(actions)),num_classes=vocab_len))\n",
    "            else:\n",
    "                result.append(np.zeros(vocab_len))\n",
    "                \n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_db_output(to_categorical([[t.word_index['being']]]),['john'],to_categorical([[t.word_index['being']]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temp(m):\n",
    "    wt=[]\n",
    "    for w in m.weights:\n",
    "        we=K.eval(w).flatten() \n",
    "        if we.shape==0: continue\n",
    "        wt+=list(we)\n",
    "    return np.array(wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1440 samples, validate on 360 samples\n",
      "Epoch 1/1\n",
      "1440/1440 [==============================] - 0s 65us/step - loss: 7.5227e-06 - val_loss: 7.2169e-06\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-123-ba70d6e3dda9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mYdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_db_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXdb_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_XN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mdb_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXdb_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mYdb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_Y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mii\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdb_model_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/miniconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/lib/miniconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/miniconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/miniconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2633\u001b[0m                                 \u001b[0mfeed_symbols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2635\u001b[0;31m                                 session)\n\u001b[0m\u001b[1;32m   2636\u001b[0m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/miniconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_make_callable\u001b[0;34m(self, feed_arrays, feed_symbols, symbol_vals, session)\u001b[0m\n\u001b[1;32m   2585\u001b[0m         \u001b[0mcallable_opts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2586\u001b[0m         \u001b[0;31m# Create callable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2587\u001b[0;31m         \u001b[0mcallable_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable_from_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallable_opts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2588\u001b[0m         \u001b[0;31m# Cache parameters corresponding to the generated callable, so that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2589\u001b[0m         \u001b[0;31m# we can detect future mismatches and refresh the callable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_make_callable_from_options\u001b[0;34m(self, callable_options)\u001b[0m\n\u001b[1;32m   1412\u001b[0m     \"\"\"\n\u001b[1;32m   1413\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1414\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mBaseSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallable_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, session, callable_options)\u001b[0m\n\u001b[1;32m   1366\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m           self._handle = tf_session.TF_SessionMakeCallable(\n\u001b[0;32m-> 1368\u001b[0;31m               session._session, options_ptr, status)\n\u001b[0m\u001b[1;32m   1369\u001b[0m       \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m         \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_DeleteBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dist = np.random.permutation(len(X_in))\n",
    "batch_size=64\n",
    "X_inr = X_in[dist]\n",
    "X_name_r = np.array(X_name)[dist]\n",
    "Y_inr = Y_in[dist]\n",
    "for ii in range(100):\n",
    "    batch_X = X_inr\n",
    "    batch_Y = Y_inr\n",
    "    batch_XN = X_name_r\n",
    "\n",
    "    Xdb_pred = model_rnn.predict(batch_X)\n",
    "    Ydb = get_db_output(Xdb_pred,batch_XN,batch_Y)\n",
    "    db_model.fit(Xdb_pred,Ydb,batch_size=batch_size,epochs=1,validation_split=0.2)\n",
    "    model.fit(batch_X,batch_Y,batch_size=batch_size,epochs=10,validation_split=0.2)\n",
    "    if ii%5==0: db_model_fit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion: The model sticks to one of the names like 'john', after which there is no gradient\n",
    "\n",
    "### Hypothesis 3: If we penalize the model such that it produces output similar to the input it might give the correct answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=0.2\n",
    "def loss(y_true, y_pred):\n",
    "    #y_pred[0] is the inner output, y_pred[1] is the outer output\n",
    "    s = K.binary_crossentropy(y_true,y_pred)\n",
    "    return s\n",
    "\n",
    "def loss_inner(y_true,y_pred):\n",
    "    a1 = K.batch_dot(y_true,y_pred,axes=[1,1])\n",
    "    \n",
    "    a2 = K.batch_dot(1-y_true,y_pred,axes=[1,1])\n",
    "    pred=K.concatenate([a1,a2],axis=1)\n",
    "    true=K.variable(value=[[1,0]])\n",
    "    true=tf.tile(true,[tf.shape(y_true)[0],1])\n",
    "    return l*K.categorical_crossentropy(true,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "out_3 = frozen_db_model(model_rnn.output)\n",
    "model_3 = Model(inputs=[model_rnn.input],outputs=[model_rnn.output,out_3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_3.compile(optimizer='adam',loss=[loss_inner,loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1440 samples, validate on 360 samples\n",
      "Epoch 1/1\n",
      "1440/1440 [==============================] - 0s 66us/step - loss: 0.0366 - val_loss: 0.0363\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "Epoch 1/10\n",
      "1440/1440 [==============================] - 2s 1ms/step - loss: 0.2082 - dense_3_loss: 0.0667 - frozen_db_model_loss: 0.1415 - val_loss: 0.1857 - val_dense_3_loss: 0.0294 - val_frozen_db_model_loss: 0.1563\n",
      "Epoch 2/10\n",
      "1440/1440 [==============================] - 1s 390us/step - loss: 0.1801 - dense_3_loss: 0.0227 - frozen_db_model_loss: 0.1574 - val_loss: 0.1757 - val_dense_3_loss: 0.0187 - val_frozen_db_model_loss: 0.1570\n",
      "Epoch 3/10\n",
      "1440/1440 [==============================] - 1s 402us/step - loss: 0.1751 - dense_3_loss: 0.0165 - frozen_db_model_loss: 0.1586 - val_loss: 0.1731 - val_dense_3_loss: 0.0138 - val_frozen_db_model_loss: 0.1593\n",
      "Epoch 4/10\n",
      "1440/1440 [==============================] - 1s 401us/step - loss: 0.1732 - dense_3_loss: 0.0124 - frozen_db_model_loss: 0.1607 - val_loss: 0.1717 - val_dense_3_loss: 0.0112 - val_frozen_db_model_loss: 0.1605\n",
      "Epoch 5/10\n",
      "1440/1440 [==============================] - 1s 392us/step - loss: 0.1720 - dense_3_loss: 0.0106 - frozen_db_model_loss: 0.1614 - val_loss: 0.1708 - val_dense_3_loss: 0.0098 - val_frozen_db_model_loss: 0.1610\n",
      "Epoch 6/10\n",
      "1440/1440 [==============================] - 1s 390us/step - loss: 0.1712 - dense_3_loss: 0.0092 - frozen_db_model_loss: 0.1620 - val_loss: 0.1700 - val_dense_3_loss: 0.0084 - val_frozen_db_model_loss: 0.1617\n",
      "Epoch 7/10\n",
      "1440/1440 [==============================] - 1s 429us/step - loss: 0.1706 - dense_3_loss: 0.0080 - frozen_db_model_loss: 0.1626 - val_loss: 0.1695 - val_dense_3_loss: 0.0074 - val_frozen_db_model_loss: 0.1620\n",
      "Epoch 8/10\n",
      "1440/1440 [==============================] - 1s 428us/step - loss: 0.1700 - dense_3_loss: 0.0072 - frozen_db_model_loss: 0.1628 - val_loss: 0.1690 - val_dense_3_loss: 0.0066 - val_frozen_db_model_loss: 0.1624\n",
      "Epoch 9/10\n",
      "1440/1440 [==============================] - 1s 430us/step - loss: 0.1696 - dense_3_loss: 0.0064 - frozen_db_model_loss: 0.1632 - val_loss: 0.1686 - val_dense_3_loss: 0.0060 - val_frozen_db_model_loss: 0.1626\n",
      "Epoch 10/10\n",
      "1440/1440 [==============================] - 1s 432us/step - loss: 0.1692 - dense_3_loss: 0.0058 - frozen_db_model_loss: 0.1634 - val_loss: 0.1682 - val_dense_3_loss: 0.0054 - val_frozen_db_model_loss: 0.1628\n",
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/1\n",
      "80000/80000 [==============================] - 5s 61us/step - loss: 0.0161 - val_loss: 0.0156\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "Epoch 1/1\n",
      "1440/1440 [==============================] - 0s 62us/step - loss: 0.0876 - val_loss: 0.0874\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "Epoch 1/10\n",
      "1440/1440 [==============================] - 1s 394us/step - loss: 0.0920 - dense_3_loss: 0.0048 - frozen_db_model_loss: 0.0872 - val_loss: 0.0917 - val_dense_3_loss: 0.0043 - val_frozen_db_model_loss: 0.0874\n",
      "Epoch 2/10\n",
      "1440/1440 [==============================] - 1s 405us/step - loss: 0.0912 - dense_3_loss: 0.0040 - frozen_db_model_loss: 0.0872 - val_loss: 0.0911 - val_dense_3_loss: 0.0037 - val_frozen_db_model_loss: 0.0874\n",
      "Epoch 3/10\n",
      "1440/1440 [==============================] - 1s 394us/step - loss: 0.0907 - dense_3_loss: 0.0035 - frozen_db_model_loss: 0.0872 - val_loss: 0.0906 - val_dense_3_loss: 0.0032 - val_frozen_db_model_loss: 0.0874\n",
      "Epoch 4/10\n",
      "1440/1440 [==============================] - 1s 435us/step - loss: 0.0903 - dense_3_loss: 0.0031 - frozen_db_model_loss: 0.0872 - val_loss: 0.0903 - val_dense_3_loss: 0.0029 - val_frozen_db_model_loss: 0.0874\n",
      "Epoch 5/10\n",
      "1440/1440 [==============================] - 1s 411us/step - loss: 0.0899 - dense_3_loss: 0.0028 - frozen_db_model_loss: 0.0872 - val_loss: 0.0899 - val_dense_3_loss: 0.0025 - val_frozen_db_model_loss: 0.0874\n",
      "Epoch 6/10\n",
      "1440/1440 [==============================] - 1s 404us/step - loss: 0.0896 - dense_3_loss: 0.0024 - frozen_db_model_loss: 0.0872 - val_loss: 0.0897 - val_dense_3_loss: 0.0023 - val_frozen_db_model_loss: 0.0874\n",
      "Epoch 7/10\n",
      "1440/1440 [==============================] - 1s 407us/step - loss: 0.0894 - dense_3_loss: 0.0022 - frozen_db_model_loss: 0.0872 - val_loss: 0.0894 - val_dense_3_loss: 0.0020 - val_frozen_db_model_loss: 0.0874\n",
      "Epoch 8/10\n",
      "1440/1440 [==============================] - 1s 404us/step - loss: 0.0892 - dense_3_loss: 0.0020 - frozen_db_model_loss: 0.0872 - val_loss: 0.0892 - val_dense_3_loss: 0.0018 - val_frozen_db_model_loss: 0.0874\n",
      "Epoch 9/10\n",
      "1440/1440 [==============================] - 1s 398us/step - loss: 0.0890 - dense_3_loss: 0.0018 - frozen_db_model_loss: 0.0872 - val_loss: 0.0891 - val_dense_3_loss: 0.0017 - val_frozen_db_model_loss: 0.0874\n",
      "Epoch 10/10\n",
      "1440/1440 [==============================] - 1s 438us/step - loss: 0.0888 - dense_3_loss: 0.0016 - frozen_db_model_loss: 0.0872 - val_loss: 0.0889 - val_dense_3_loss: 0.0015 - val_frozen_db_model_loss: 0.0874\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "Epoch 1/1\n",
      "1440/1440 [==============================] - 0s 53us/step - loss: 0.0872 - val_loss: 0.0876\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "Epoch 1/10\n",
      "1440/1440 [==============================] - 1s 393us/step - loss: 0.0884 - dense_3_loss: 0.0015 - frozen_db_model_loss: 0.0869 - val_loss: 0.0890 - val_dense_3_loss: 0.0014 - val_frozen_db_model_loss: 0.0876\n",
      "Epoch 2/10\n",
      "1440/1440 [==============================] - 1s 395us/step - loss: 0.0883 - dense_3_loss: 0.0013 - frozen_db_model_loss: 0.0869 - val_loss: 0.0888 - val_dense_3_loss: 0.0012 - val_frozen_db_model_loss: 0.0876\n",
      "Epoch 3/10\n",
      "1440/1440 [==============================] - 1s 401us/step - loss: 0.0882 - dense_3_loss: 0.0012 - frozen_db_model_loss: 0.0869 - val_loss: 0.0888 - val_dense_3_loss: 0.0012 - val_frozen_db_model_loss: 0.0876\n",
      "Epoch 4/10\n",
      "1440/1440 [==============================] - 1s 399us/step - loss: 0.0881 - dense_3_loss: 0.0011 - frozen_db_model_loss: 0.0869 - val_loss: 0.0887 - val_dense_3_loss: 0.0011 - val_frozen_db_model_loss: 0.0876\n",
      "Epoch 5/10\n",
      "1440/1440 [==============================] - 1s 402us/step - loss: 0.0880 - dense_3_loss: 0.0011 - frozen_db_model_loss: 0.0869 - val_loss: 0.0886 - val_dense_3_loss: 9.8774e-04 - val_frozen_db_model_loss: 0.0876\n",
      "Epoch 6/10\n",
      "1440/1440 [==============================] - 1s 400us/step - loss: 0.0879 - dense_3_loss: 9.7931e-04 - frozen_db_model_loss: 0.0869 - val_loss: 0.0885 - val_dense_3_loss: 9.1200e-04 - val_frozen_db_model_loss: 0.0876\n",
      "Epoch 7/10\n",
      "1440/1440 [==============================] - 1s 404us/step - loss: 0.0879 - dense_3_loss: 9.1134e-04 - frozen_db_model_loss: 0.0869 - val_loss: 0.0884 - val_dense_3_loss: 8.5347e-04 - val_frozen_db_model_loss: 0.0876\n",
      "Epoch 8/10\n",
      "1440/1440 [==============================] - 1s 402us/step - loss: 0.0878 - dense_3_loss: 8.5565e-04 - frozen_db_model_loss: 0.0869 - val_loss: 0.0884 - val_dense_3_loss: 8.0273e-04 - val_frozen_db_model_loss: 0.0876\n",
      "Epoch 9/10\n",
      "1440/1440 [==============================] - 1s 404us/step - loss: 0.0877 - dense_3_loss: 8.0294e-04 - frozen_db_model_loss: 0.0869 - val_loss: 0.0883 - val_dense_3_loss: 7.5522e-04 - val_frozen_db_model_loss: 0.0876\n",
      "Epoch 10/10\n",
      "1440/1440 [==============================] - 1s 418us/step - loss: 0.0877 - dense_3_loss: 7.5454e-04 - frozen_db_model_loss: 0.0869 - val_loss: 0.0883 - val_dense_3_loss: 7.1389e-04 - val_frozen_db_model_loss: 0.0876\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "Epoch 1/1\n",
      "1440/1440 [==============================] - 0s 53us/step - loss: 0.0871 - val_loss: 0.0880\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "Epoch 1/10\n",
      "1440/1440 [==============================] - 1s 418us/step - loss: 0.0876 - dense_3_loss: 7.1498e-04 - frozen_db_model_loss: 0.0869 - val_loss: 0.0887 - val_dense_3_loss: 6.7249e-04 - val_frozen_db_model_loss: 0.0880\n",
      "Epoch 2/10\n",
      "1440/1440 [==============================] - 1s 409us/step - loss: 0.0876 - dense_3_loss: 6.7297e-04 - frozen_db_model_loss: 0.0869 - val_loss: 0.0887 - val_dense_3_loss: 6.4053e-04 - val_frozen_db_model_loss: 0.0880\n",
      "Epoch 3/10\n",
      "1440/1440 [==============================] - 1s 399us/step - loss: 0.0875 - dense_3_loss: 6.3858e-04 - frozen_db_model_loss: 0.0869 - val_loss: 0.0886 - val_dense_3_loss: 6.0463e-04 - val_frozen_db_model_loss: 0.0880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      "1440/1440 [==============================] - 1s 391us/step - loss: 0.0875 - dense_3_loss: 6.0932e-04 - frozen_db_model_loss: 0.0869 - val_loss: 0.0886 - val_dense_3_loss: 5.7557e-04 - val_frozen_db_model_loss: 0.0880\n",
      "Epoch 5/10\n",
      "1440/1440 [==============================] - 1s 408us/step - loss: 0.0875 - dense_3_loss: 5.8105e-04 - frozen_db_model_loss: 0.0869 - val_loss: 0.0886 - val_dense_3_loss: 5.5768e-04 - val_frozen_db_model_loss: 0.0880\n",
      "Epoch 6/10\n",
      "1440/1440 [==============================] - 1s 400us/step - loss: 0.0874 - dense_3_loss: 5.5282e-04 - frozen_db_model_loss: 0.0869 - val_loss: 0.0885 - val_dense_3_loss: 5.2471e-04 - val_frozen_db_model_loss: 0.0880\n",
      "Epoch 7/10\n",
      "1440/1440 [==============================] - 1s 393us/step - loss: 0.0874 - dense_3_loss: 5.2489e-04 - frozen_db_model_loss: 0.0869 - val_loss: 0.0885 - val_dense_3_loss: 4.9582e-04 - val_frozen_db_model_loss: 0.0880\n",
      "Epoch 8/10\n",
      "1440/1440 [==============================] - 1s 427us/step - loss: 0.0874 - dense_3_loss: 5.0394e-04 - frozen_db_model_loss: 0.0869 - val_loss: 0.0885 - val_dense_3_loss: 4.7604e-04 - val_frozen_db_model_loss: 0.0880\n",
      "Epoch 9/10\n",
      "1440/1440 [==============================] - 1s 400us/step - loss: 0.0874 - dense_3_loss: 4.7750e-04 - frozen_db_model_loss: 0.0869 - val_loss: 0.0885 - val_dense_3_loss: 4.5607e-04 - val_frozen_db_model_loss: 0.0880\n",
      "Epoch 10/10\n",
      "1440/1440 [==============================] - 1s 394us/step - loss: 0.0873 - dense_3_loss: 4.5743e-04 - frozen_db_model_loss: 0.0869 - val_loss: 0.0885 - val_dense_3_loss: 4.3325e-04 - val_frozen_db_model_loss: 0.0880\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "Epoch 1/1\n",
      "1440/1440 [==============================] - 0s 58us/step - loss: 0.0871 - val_loss: 0.0881\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "Epoch 1/10\n",
      "1440/1440 [==============================] - 1s 429us/step - loss: 0.0873 - dense_3_loss: 4.3887e-04 - frozen_db_model_loss: 0.0868 - val_loss: 0.0885 - val_dense_3_loss: 4.1598e-04 - val_frozen_db_model_loss: 0.0881\n",
      "Epoch 2/10\n",
      "1440/1440 [==============================] - 1s 436us/step - loss: 0.0873 - dense_3_loss: 4.2031e-04 - frozen_db_model_loss: 0.0868 - val_loss: 0.0885 - val_dense_3_loss: 4.0354e-04 - val_frozen_db_model_loss: 0.0881\n",
      "Epoch 3/10\n",
      "1440/1440 [==============================] - 1s 416us/step - loss: 0.0872 - dense_3_loss: 4.0148e-04 - frozen_db_model_loss: 0.0868 - val_loss: 0.0885 - val_dense_3_loss: 3.8262e-04 - val_frozen_db_model_loss: 0.0881\n",
      "Epoch 4/10\n",
      "1440/1440 [==============================] - 1s 412us/step - loss: 0.0872 - dense_3_loss: 3.8575e-04 - frozen_db_model_loss: 0.0868 - val_loss: 0.0885 - val_dense_3_loss: 3.6433e-04 - val_frozen_db_model_loss: 0.0881\n",
      "Epoch 5/10\n",
      "1440/1440 [==============================] - 1s 427us/step - loss: 0.0872 - dense_3_loss: 3.6945e-04 - frozen_db_model_loss: 0.0868 - val_loss: 0.0885 - val_dense_3_loss: 3.4981e-04 - val_frozen_db_model_loss: 0.0881\n",
      "Epoch 6/10\n",
      "1440/1440 [==============================] - 1s 429us/step - loss: 0.0872 - dense_3_loss: 3.5548e-04 - frozen_db_model_loss: 0.0868 - val_loss: 0.0885 - val_dense_3_loss: 3.3977e-04 - val_frozen_db_model_loss: 0.0881\n",
      "Epoch 7/10\n",
      "1408/1440 [============================>.] - ETA: 0s - loss: 0.0872 - dense_3_loss: 3.4443e-04 - frozen_db_model_loss: 0.0868"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-24be1e81dda3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mdb_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXdb_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mYdb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mmid_in\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mmodel_3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmid_in\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_Y\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mii\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdb_model_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/miniconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/lib/miniconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    210\u001b[0m                         val_outs = test_loop(model, val_f, val_ins,\n\u001b[1;32m    211\u001b[0m                                              \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m                                              verbose=0)\n\u001b[0m\u001b[1;32m    213\u001b[0m                         \u001b[0mval_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m                         \u001b[0;31m# Same labels assumed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/miniconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mtest_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    390\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/miniconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/miniconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dist = np.random.permutation(len(X_in))\n",
    "batch_size=64\n",
    "X_inr = X_in[dist]\n",
    "X_name_r = np.array(X_name)[dist]\n",
    "Y_inr = Y_in[dist]\n",
    "for ii in range(10):\n",
    "    batch_X = X_inr\n",
    "    batch_Y = Y_inr\n",
    "    batch_XN = X_name_r\n",
    "\n",
    "    Xdb_pred = model_rnn.predict(batch_X)\n",
    "    Ydb = get_db_output(Xdb_pred,batch_XN,batch_Y)\n",
    "    db_model.fit(Xdb_pred,Ydb,batch_size=batch_size,epochs=1,validation_split=0.2)\n",
    "    mid_in=np.array(np.sum(batch_X,axis=1)>0,dtype='int32')\n",
    "    model_3.fit(batch_X,[mid_in,batch_Y],batch_size=batch_size,epochs=10,validation_split=0.2)\n",
    "    if ii%5==0: db_model_fit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what is being done by amit?']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ii=1222\n",
    "X[ii:ii+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[9.79744727e-05, 9.17079233e-05, 2.90108846e-06, 5.79227759e-08,\n",
       "         6.49084342e-08, 1.03944608e-07, 1.63793146e-07, 3.55146085e-07,\n",
       "         7.39774677e-08, 9.96569753e-01, 3.04787769e-04, 7.20099080e-04,\n",
       "         7.03438476e-04, 8.67077091e-04, 6.39674894e-04, 1.36158604e-07,\n",
       "         7.18421518e-08, 5.35556168e-08, 1.41160015e-07, 1.52004006e-07,\n",
       "         7.61615908e-08, 1.19727844e-07, 1.61565637e-07, 1.10882326e-07,\n",
       "         1.46888354e-07, 9.59928741e-08, 6.59995436e-08, 1.13530660e-07,\n",
       "         8.32644815e-08, 8.02716187e-08, 2.36035376e-07]], dtype=float32),\n",
       " array([[8.25720326e-06, 1.41154806e-05, 1.28176061e-05, 1.37305924e-05,\n",
       "         1.62413780e-05, 1.69007890e-05, 8.44069928e-06, 1.61130065e-05,\n",
       "         1.02646682e-05, 7.36240463e-06, 1.21889325e-05, 1.32582418e-05,\n",
       "         9.75085368e-06, 1.45800705e-05, 8.48550098e-06, 1.77180082e-01,\n",
       "         1.28883228e-01, 1.39049562e-05, 1.81803882e-01, 1.16460496e-05,\n",
       "         1.14678378e-05, 1.92572355e-01, 1.74534872e-01, 1.21998401e-05,\n",
       "         1.46989062e-01, 9.83875088e-06, 1.22070905e-05, 1.01957994e-05,\n",
       "         1.14703207e-05, 1.10546935e-05, 1.17641175e-05]], dtype=float32)]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=model_rnn.predict(X_in[ii:ii+1])\n",
    "model_3.predict(X_in[ii:ii+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.79744727e-05, 9.17079233e-05, 2.90108846e-06, 5.79227759e-08,\n",
       "        6.49084342e-08, 1.03944608e-07, 1.63793146e-07, 3.55146085e-07,\n",
       "        7.39774677e-08, 9.96569753e-01, 3.04787769e-04, 7.20099080e-04,\n",
       "        7.03438476e-04, 8.67077091e-04, 6.39674894e-04, 1.36158604e-07,\n",
       "        7.18421518e-08, 5.35556168e-08, 1.41160015e-07, 1.52004006e-07,\n",
       "        7.61615908e-08, 1.19727844e-07, 1.61565637e-07, 1.10882326e-07,\n",
       "        1.46888354e-07, 9.59928741e-08, 6.59995436e-08, 1.13530660e-07,\n",
       "        8.32644815e-08, 8.02716187e-08, 2.36035376e-07]], dtype=float32)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'is',\n",
       " 2: 'what',\n",
       " 3: 'i',\n",
       " 4: 'doing',\n",
       " 5: 'being',\n",
       " 6: 'done',\n",
       " 7: 'by',\n",
       " 8: 'upto',\n",
       " 9: 'amit',\n",
       " 10: 'ketan',\n",
       " 11: 'aparna',\n",
       " 12: 'dog',\n",
       " 13: 'john',\n",
       " 14: 'aman',\n",
       " 15: 'singing',\n",
       " 16: 'climbing',\n",
       " 17: 'believe',\n",
       " 18: 'riding',\n",
       " 19: 'my',\n",
       " 20: 'guess',\n",
       " 21: 'dancing',\n",
       " 22: 'skating',\n",
       " 23: 'think',\n",
       " 24: 'playing',\n",
       " 25: 'guessdog',\n",
       " 26: 'guessketan',\n",
       " 27: 'guessamit',\n",
       " 28: 'guessjohn',\n",
       " 29: 'guessaman',\n",
       " 30: 'guessaparna'}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.25720326e-06, 1.41154806e-05, 1.28176061e-05, 1.37305924e-05,\n",
       "        1.62413780e-05, 1.69007890e-05, 8.44069928e-06, 1.61130065e-05,\n",
       "        1.02646682e-05, 7.36240463e-06, 1.21889325e-05, 1.32582418e-05,\n",
       "        9.75085368e-06, 1.45800705e-05, 8.48550098e-06, 1.77180082e-01,\n",
       "        1.28883228e-01, 1.39049562e-05, 1.81803882e-01, 1.16460496e-05,\n",
       "        1.14678378e-05, 1.92572355e-01, 1.74534872e-01, 1.21998401e-05,\n",
       "        1.46989062e-01, 9.83875088e-06, 1.22070905e-05, 1.01957994e-05,\n",
       "        1.14703207e-05, 1.10546935e-05, 1.17641175e-05]], dtype=float32)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_model.predict(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('amit', 0.99656975),\n",
       " ('john', 0.0008670771),\n",
       " ('aparna', 0.0007200991),\n",
       " ('dog', 0.0007034385),\n",
       " ('aman', 0.0006396749),\n",
       " ('ketan', 0.00030478777),\n",
       " '',\n",
       " ('is', 9.170792e-05),\n",
       " ('what', 2.9010885e-06),\n",
       " ('by', 3.5514608e-07),\n",
       " ('guessaparna', 2.3603538e-07),\n",
       " ('done', 1.6379315e-07),\n",
       " ('skating', 1.6156564e-07),\n",
       " ('my', 1.52004e-07),\n",
       " ('playing', 1.4688835e-07),\n",
       " ('riding', 1.4116002e-07),\n",
       " ('singing', 1.361586e-07),\n",
       " ('dancing', 1.1972784e-07),\n",
       " ('guessamit', 1.1353066e-07),\n",
       " ('think', 1.10882326e-07),\n",
       " ('being', 1.0394461e-07),\n",
       " ('guessdog', 9.5992874e-08),\n",
       " ('guessjohn', 8.326448e-08),\n",
       " ('guessaman', 8.027162e-08),\n",
       " ('guess', 7.616159e-08),\n",
       " ('upto', 7.397747e-08),\n",
       " ('climbing', 7.184215e-08),\n",
       " ('guessketan', 6.5999544e-08),\n",
       " ('doing', 6.4908434e-08),\n",
       " ('i', 5.7922776e-08),\n",
       " ('believe', 5.3555617e-08)]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(t.index_word[i],y[0][i]) if i!=0 else '' for i in y.argsort(axis=-1)[0][-1::-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_in[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[to_categorical(t.word_index['skating'],num_classes=vocab_len)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.3809131e-07, 6.3723871e-07, 1.3261200e-06, 1.1625814e-06,\n",
       "        1.2117929e-06, 7.5841649e-07, 1.3209815e-06, 1.5397128e-06,\n",
       "        7.1623776e-07, 8.6926002e-07, 1.2681979e-06, 1.3714529e-06,\n",
       "        8.4603505e-07, 1.1133515e-06, 7.8123770e-07, 8.6682286e-07,\n",
       "        8.9299738e-07, 1.7747351e-06, 1.2850279e-06, 9.9320982e-07,\n",
       "        1.2195118e-06, 1.1679647e-06, 7.4824857e-07, 7.6966069e-07,\n",
       "        1.0867199e-06, 1.2022308e-06, 1.0919276e-06, 9.5226477e-07,\n",
       "        5.9434461e-07, 9.9766692e-07, 9.7066777e-07]], dtype=float32)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_model.predict(np.array([to_categorical(t.word_index['skating'],num_classes=vocab_len)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONCLUSION SUCCESS: The model converges. \n",
    "However, there is a problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=model_rnn.predict(to_categorical(pad_sequences(t.texts_to_sequences([\"ketan\"]),maxlen=10),num_classes=vocab_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.1782163e-03, 1.4886333e-03, 4.3853241e-05, 5.4093920e-07,\n",
       "        6.0350908e-07, 8.2087166e-07, 7.8087805e-07, 9.1832135e-07,\n",
       "        9.9023760e-07, 4.5584120e-02, 8.6722761e-01, 1.8921386e-02,\n",
       "        7.7100899e-03, 1.8320702e-02, 3.9507180e-02, 7.2279369e-07,\n",
       "        8.3128401e-07, 6.1744743e-07, 1.3881496e-06, 1.2875290e-06,\n",
       "        8.4156670e-07, 9.6068334e-07, 1.2291653e-06, 6.0316040e-07,\n",
       "        6.2408913e-07, 6.0711238e-07, 7.1035311e-07, 1.0104909e-06,\n",
       "        5.1053144e-07, 1.0117416e-06, 6.1792809e-07]], dtype=float32)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'john'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.index_word[13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating full sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import RepeatVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input((10,vocab_len))\n",
    "encoder = LSTM(50,return_state=True)\n",
    "out,out_h,out_c=encoder(inp)\n",
    "out = Dense(vocab_len,activation='softmax')(out)\n",
    "model_rnn_2=Model(inputs=[inp],outputs=out)\n",
    "\n",
    "out_3 = frozen_db_model(model_rnn_2.output)\n",
    "out_35 = RepeatVector(10)(out_3)\n",
    "decoder = LSTM(50,return_sequences=True,return_state=True)\n",
    "out_4,_,_= decoder(out_35,initial_state=[out_h,out_c])\n",
    "out_4 = Dense(vocab_len,activation='softmax')(out_4)\n",
    "model_4 = Model(inputs=[model_rnn_2.input],outputs=[model_rnn_2.output,out_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4.compile(optimizer='adam',loss=[loss_inner,keras.losses.categorical_crossentropy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_in_full = [Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
