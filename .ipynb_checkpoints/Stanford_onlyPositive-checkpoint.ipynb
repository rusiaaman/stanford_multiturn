{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/miniconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/usr/lib/miniconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/miniconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='./kvret_dataset_public/'\n",
    "with open(path+'kvret_train_public.json') as f:\n",
    "    dat=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path+'kvret_dev_public.json') as f:\n",
    "    valid_dat=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path+'kvret_test_public.json') as f:\n",
    "    test_dat=json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "dic = defaultdict(str)\n",
    "for d in dat:\n",
    "    for _d in d['dialogue']:\n",
    "        dic.update(_d['data'].get('slots',{}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "dic = set([])\n",
    "for d in dat:\n",
    "    for _d in d['dialogue']:\n",
    "        slots = _d['data'].get('slots')\n",
    "        if not slots: continue\n",
    "        dic.update([slots.get('distance')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "dic = defaultdict(str)\n",
    "for d in dat:\n",
    "    for _d in d['dialogue']:\n",
    "        dic.update(_d.get('data',{}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "requested_slots = list(dic['requested'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['kb', 'task', 'uuid'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['scenario'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'poi', 'sunday', 'date', 'agenda', 'wednesday', 'party', 'traffic_info', 'address', 'tuesday', 'monday', 'location', 'friday', 'thursday', 'event', 'saturday', 'today', 'room', 'distance', 'poi_type', 'time'}\n"
     ]
    }
   ],
   "source": [
    "s=set([])\n",
    "for d in dat:\n",
    "    try:\n",
    "        keys=d['scenario']['kb']['column_names']\n",
    "    except:\n",
    "        continue\n",
    "    s.update(keys)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'no traffic', 'road block nearby', 'car collision nearby', 'heavy traffic', 'moderate traffic'}\n"
     ]
    }
   ],
   "source": [
    "s=set([])\n",
    "for d in dat:\n",
    "    try:\n",
    "        keys=[t['traffic_info'] for t in d['scenario']['kb']['items'] ]\n",
    "    except:\n",
    "        continue\n",
    "    s.update(keys)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'location information', 'weekly forecast', 'calendar'}\n"
     ]
    }
   ],
   "source": [
    "s=set([])\n",
    "for d in dat:\n",
    "    try:\n",
    "        keys=[d['scenario']['kb']['kb_title']]\n",
    "    except:\n",
    "        continue\n",
    "    s.update(keys)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'schedule', 'weather', 'navigate'}\n"
     ]
    }
   ],
   "source": [
    "s=set([])\n",
    "for d in dat:\n",
    "    try:\n",
    "        keys=[d['scenario']['task']['intent']]\n",
    "    except:\n",
    "        print(d)\n",
    "        continue\n",
    "    s.update(keys)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'set'>, {'location information': {'navigate'}, 'calendar': {'schedule'}, 'weekly forecast': {'weather'}})\n"
     ]
    }
   ],
   "source": [
    "s=defaultdict(set)\n",
    "for d in dat:\n",
    "    try:\n",
    "        s[d['scenario']['kb']['kb_title']].update([d['scenario']['task']['intent']])\n",
    "    except:\n",
    "        print(d)\n",
    "        continue\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'set'>, {'navigate': {'poi', 'traffic_info', 'address', 'distance', 'poi_type'}, 'schedule': {'date', 'agenda', 'party', 'event', 'room', 'time'}, 'weather': {'sunday', 'wednesday', 'tuesday', 'today', 'monday', 'location', 'friday', 'thursday', 'saturday'}})\n"
     ]
    }
   ],
   "source": [
    "s=defaultdict(set)\n",
    "for d in dat:\n",
    "    try:\n",
    "        s[d['scenario']['task']['intent']].update(d['scenario']['kb']['column_names'])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dialogue': [{'turn': 'driver', 'data': {'end_dialogue': False, 'utterance': 'check forecast for new york'}}, {'turn': 'assistant', 'data': {'end_dialogue': False, 'requested': {'weather_attribute': True, 'date': False, 'location': True}, 'slots': {'location': ' new york'}, 'utterance': 'The weather this week will be hail and rain on Thursday and Sunday, with the lowest temperature being 20F and the highest 90F, Monday will be the only hot day. '}}, {'turn': 'driver', 'data': {'end_dialogue': False, 'utterance': 'Will it be overcast on friday?'}}, {'turn': 'assistant', 'data': {'end_dialogue': False, 'requested': {'weather_attribute': True, 'date': True, 'location': False}, 'slots': {'weather_attribute': 'overcast', 'date': 'Friday'}, 'utterance': 'On Friday it will be cloudy on New York'}}, {'turn': 'driver', 'data': {'end_dialogue': False, 'utterance': 'Thank you!'}}, {'turn': 'assistant', 'data': {'end_dialogue': True, 'requested': {'weather_attribute': False, 'date': False, 'location': False}, 'slots': {}, 'utterance': \"You're welcome!\"}}], 'scenario': {'kb': {'items': [{'monday': 'stormy, low of 50F, high of 70F', 'tuesday': 'cloudy, low of 20F, high of 40F', 'friday': 'windy, low of 20F, high of 40F', 'wednesday': 'clear skies, low of 50F, high of 60F', 'thursday': 'stormy, low of 50F, high of 70F', 'sunday': 'hail, low of 30F, high of 50F', 'location': 'manhattan', 'saturday': 'snow, low of 60F, high of 70F', 'today': 'monday'}, {'monday': 'overcast, low of 50F, high of 70F', 'tuesday': 'stormy, low of 90F, high of 100F', 'friday': 'clear skies, low of 70F, high of 80F', 'wednesday': 'frost, low of 50F, high of 60F', 'thursday': 'snow, low of 80F, high of 90F', 'sunday': 'dry, low of 70F, high of 80F', 'location': 'camarillo', 'saturday': 'blizzard, low of 40F, high of 50F', 'today': 'monday'}, {'monday': 'dry, low of 50F, high of 70F', 'tuesday': 'warm, low of 80F, high of 90F', 'friday': 'cloudy, low of 70F, high of 80F', 'wednesday': 'hail, low of 20F, high of 40F', 'thursday': 'blizzard, low of 40F, high of 60F', 'sunday': 'stormy, low of 90F, high of 100F', 'location': 'menlo park', 'saturday': 'foggy, low of 50F, high of 60F', 'today': 'monday'}, {'monday': 'hot, low of 70F, high of 90F', 'tuesday': 'foggy, low of 70F, high of 90F', 'friday': 'cloudy, low of 70F, high of 90F', 'wednesday': 'dry, low of 40F, high of 50F', 'thursday': 'hail, low of 40F, high of 50F', 'sunday': 'rain, low of 20F, high of 30F', 'location': 'new york', 'saturday': 'clear skies, low of 70F, high of 90F', 'today': 'monday'}, {'monday': 'windy, low of 70F, high of 80F', 'tuesday': 'overcast, low of 40F, high of 50F', 'friday': 'hail, low of 60F, high of 70F', 'wednesday': 'hail, low of 90F, high of 100F', 'thursday': 'rain, low of 80F, high of 100F', 'sunday': 'frost, low of 20F, high of 30F', 'location': 'corona', 'saturday': 'warm, low of 60F, high of 80F', 'today': 'monday'}, {'monday': 'cloudy, low of 90F, high of 100F', 'tuesday': 'dry, low of 30F, high of 40F', 'friday': 'foggy, low of 20F, high of 30F', 'wednesday': 'stormy, low of 80F, high of 100F', 'thursday': 'snow, low of 20F, high of 30F', 'sunday': 'drizzle, low of 50F, high of 60F', 'location': 'seattle', 'saturday': 'drizzle, low of 40F, high of 60F', 'today': 'monday'}, {'monday': 'drizzle, low of 70F, high of 80F', 'tuesday': 'overcast, low of 40F, high of 60F', 'friday': 'foggy, low of 50F, high of 60F', 'wednesday': 'overcast, low of 60F, high of 80F', 'thursday': 'snow, low of 20F, high of 40F', 'sunday': 'cloudy, low of 30F, high of 40F', 'location': 'grand rapids', 'saturday': 'dry, low of 90F, high of 100F', 'today': 'monday'}], 'column_names': ['location', 'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday', 'today'], 'kb_title': 'weekly forecast'}, 'task': {'intent': 'weather'}, 'uuid': '89cae425-6ff7-48b4-8b42-ec50b541dc63'}}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "defaultdict(<class 'set'>, {})\n"
     ]
    }
   ],
   "source": [
    "s=defaultdict(set)\n",
    "for d in dat:\n",
    "    try:\n",
    "        if d['scenario']['task']['intent'] == 'weather':\n",
    "            print(d)\n",
    "            print('\\n\\n\\n\\n')\n",
    "            break\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KB results with beilef states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'str'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "defaultdict(lambda: 'str')['hi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "def sim(a, b):\n",
    "    return SequenceMatcher(None, a.lower(), b.lower()).ratio()\n",
    "\n",
    "def close(a,b):\n",
    "    return sim(a,b)>=0.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import dateutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_op(s1,op,s2):\n",
    "    if isinstance(s1, (int, float)):\n",
    "        num1 = s1\n",
    "    else:\n",
    "        m1=re.search(r'([0-9]+)',s1)\n",
    "        if m1 is None:\n",
    "            try:\n",
    "                num1=dateutil.parser.parse(s1)\n",
    "            except ValueError:\n",
    "                return False,None\n",
    "        else:\n",
    "          num1=int(m1.group())\n",
    "           \n",
    "    if isinstance(s2,(int,float)):\n",
    "        num2 = s2\n",
    "    else:\n",
    "        m2=re.search(r'([0-9]+)',s2)\n",
    "        if m2 is None:\n",
    "            try:\n",
    "                num2=dateutil.parser.parse(s2)\n",
    "            except ValueError:\n",
    "                return False ,None     \n",
    "        else:\n",
    "          num2=int(m2.group())\n",
    "    try:\n",
    "        if op=='equal to':\n",
    "            return num1==num2,num1\n",
    "        if op=='greater than':\n",
    "            return num1>num2,num1\n",
    "        if op=='less than':\n",
    "            return num1<num2,num1\n",
    "    except TypeError:\n",
    "        return False,num1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kb_results(kb_data,kb_intent,columns,pred_kb_intent,belief_state,operation):\n",
    "    \"\"\"This function gets the kb_data, column names and intent for which the kb is received. \n",
    "    If intent identified by the bot is nto same as kb_intent no results will be returned.\n",
    "    \n",
    "    intents types: {'schedule', 'weather', 'navigate'}\n",
    "    \n",
    "    operation should have same keys as belief state with following possible values:\n",
    "    str, =, >, <, minimum, maximum  indexed from 0 to 5\n",
    "    Use None for all the values not numerical. If not None, operation would be performend\n",
    "    \"\"\"\n",
    "    #defaultdict(<class 'set'>, {'navigate': {'poi', 'distance', 'poi_type', 'traffic_info', 'address'},, 'weather': {'thursday', 'sunday', 'today', 'friday', 'wednesday', 'tuesday', 'saturday', 'location', 'monday'}})\n",
    "    if pred_kb_intent!=kb_intent:\n",
    "        return [],[]\n",
    "    if kb_data is None:\n",
    "        return [],[]\n",
    "    results = [None for _ in range(len(kb_data))]\n",
    "    confidence = np.ones(len(kb_data))\n",
    "    # column names possiblity: {'room', 'party', 'event', 'agenda', 'date', 'time'}  \n",
    "    # Note that date and time are immutable and non-comparable in current dialog, so they are treated as strings\n",
    "    col_types = defaultdict(lambda: 'str')\n",
    "    if any(k not in columns for k in belief_state.keys()):\n",
    "        return [],[]\n",
    "    for k in belief_state.keys():\n",
    "        if belief_state.get(k) is None or operation.get(k) is None:\n",
    "            return [],[]\n",
    "        min_idx = None\n",
    "        min_val = float('Inf')\n",
    "        max_idx = None\n",
    "        max_val = -float('Inf')\n",
    "        for i,items in enumerate(kb_data):\n",
    "            if results[i] == 0: continue\n",
    "            if col_types[k]=='str':\n",
    "                if items.get(k) is None:\n",
    "                    results[i]=0\n",
    "                    continue\n",
    "                results[i]=0\n",
    "                if operation[k]==0 and close(belief_state[k],items[k]):\n",
    "                    # Doing string comparison\n",
    "                    results[i]=1\n",
    "                    confidence[i] = confidence[i]*sim(belief_state.get(k),items.get(k))\n",
    "                elif operation[k]==1:\n",
    "                    #Doing equal comparison extracting the first number\n",
    "                    if num_op(belief_state[k],'equal to',items[k])[0]:\n",
    "                        results[i]=1\n",
    "                elif operation[k]==2:\n",
    "                    #Doing greater than comparison extracting the first number\n",
    "                    if num_op(belief_state[k],'less than',items[k])[0]:\n",
    "                        results[i]=1\n",
    "                elif operation[k]==3:\n",
    "                    #Doing less than comparison extracting the first number\n",
    "                    if num_op(belief_state[k],'greater than',items[k])[0]:\n",
    "                        results[i]=1\n",
    "                elif operation[k]==4:\n",
    "                    #Doing mimum comparison extracting the first number\n",
    "                    res,val = num_op(items[k],'less than',(min_val))\n",
    "                    if res:\n",
    "                        results[i]=1\n",
    "                        if min_idx is not None:\n",
    "                            results[min_idx] = 0\n",
    "                        min_val = val\n",
    "                        min_idx = i\n",
    "                elif operation[k]==5:\n",
    "                    #Doing maximum comparison extracting the first number\n",
    "                    res,val = num_op(items[k],'greater than',(max_val))\n",
    "                    if res:\n",
    "                        results[i]=1\n",
    "                        if max_idx is not None:\n",
    "                            results[max_idx] = 0\n",
    "                        max_val = val\n",
    "                        max_idx = i\n",
    "\n",
    "           \n",
    "    return np.array(results),np.array(confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "kb_data = dat[22]['scenario']['kb']['items']\n",
    "kb_intent = dat[22]['scenario']['task']['intent']\n",
    "columns = dat[22]['scenario']['kb']['column_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_kb_intent = kb_intent\n",
    "belief_state = {'traffic_info':'no traffic','distance':'6 miles'}\n",
    "operation = {'traffic_info':0,'distance':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-22-9a58e03dd849>(14)kb_results()\n",
      "-> if pred_kb_intent!=kb_intent:\n",
      "(Pdb) l\n",
      "  9  \t    Use None for all the values not numerical. If not None, operation would be performend\n",
      " 10  \t    \"\"\"\n",
      " 11  \t    #defaultdict(<class 'set'>, {'navigate': {'poi', 'distance', 'poi_type', 'traffic_info', 'address'},, 'weather': {'thursday', 'sunday', 'today', 'friday', 'wednesday', 'tuesday', 'saturday', 'location', 'monday'}})\n",
      " 12  \t    import pdb\n",
      " 13  \t    pdb.set_trace()\n",
      " 14  ->\t    if pred_kb_intent!=kb_intent:\n",
      " 15  \t        return [],[]\n",
      " 16  \t    if kb_data is None:\n",
      " 17  \t        return [],[]\n",
      " 18  \t    results = [None for _ in range(len(kb_data))]\n",
      " 19  \t    confidence = np.ones(len(kb_data))\n",
      "(Pdb) print(belief_state)\n",
      "{'traffic_info': 'no traffic', 'distance': '6 miles'}\n",
      "(Pdb) exit\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-d44968b7fd8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mkb_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkb_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkb_intent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred_kb_intent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbelief_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moperation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-22-9a58e03dd849>\u001b[0m in \u001b[0;36mkb_results\u001b[0;34m(kb_data, kb_intent, columns, pred_kb_intent, belief_state, operation)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mpred_kb_intent\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0mkb_intent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkb_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-9a58e03dd849>\u001b[0m in \u001b[0;36mkb_results\u001b[0;34m(kb_data, kb_intent, columns, pred_kb_intent, belief_state, operation)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mpred_kb_intent\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0mkb_intent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkb_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/miniconda3/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/miniconda3/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "kb_results(kb_data,kb_intent,columns,pred_kb_intent,belief_state,operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'distance': '6 miles',\n",
       " 'traffic_info': 'no traffic',\n",
       " 'poi_type': 'rest stop',\n",
       " 'address': '329 El Camino Real',\n",
       " 'poi': 'The Westin'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kb_data[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from tqdm import tqdm\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(t):\n",
    "    return word_tokenize(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2425/2425 [00:00<00:00, 101420.79it/s]\n"
     ]
    }
   ],
   "source": [
    "# collection of kb documents\n",
    "doc_kb=[]\n",
    "for d in tqdm(dat):\n",
    "    try:\n",
    "        for item in d['scenario']['kb']['items']:\n",
    "            [doc_kb.append(t)  for t in item.values()]\n",
    "    except TypeError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2425/2425 [00:00<00:00, 278548.19it/s]\n"
     ]
    }
   ],
   "source": [
    "doc_colnames=[]\n",
    "for d in tqdm(dat):\n",
    "    try:\n",
    "        item = d['scenario']['kb']['column_names']\n",
    "        [doc_colnames.append(t)  for t in item]\n",
    "    except TypeError:\n",
    "        continue\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns=list(set(doc_colnames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary for the databases\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "tokenizer=Tokenizer(filters=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(doc_kb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts([\"<SOS>\",\"<EOS>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_VOCAB_LEN = len(tokenizer.word_index)+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Also fitting in all the conversations and other things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_dict(d):\n",
    "    texts=[]\n",
    "    texts.append(\" \".join(list(d.keys())))\n",
    "    for v in d.values():\n",
    "        if isinstance(v,str):\n",
    "            texts.append(v) \n",
    "        elif isinstance(v,list):\n",
    "            texts.append(\" \".join(all_texts(v)))\n",
    "        elif isinstance(v,dict):\n",
    "            texts.append(\" \".join(all_dict(v)))\n",
    "        else:\n",
    "            try:\n",
    "                texts.append(str(v))\n",
    "            except:\n",
    "                raise Exception(f'type of v is {type(v)}')\n",
    "    return texts\n",
    "\n",
    "def all_texts(data):\n",
    "    texts = []\n",
    "    for d in data:\n",
    "        if isinstance(d,dict):\n",
    "            texts.append(\" \".join(all_dict(d)))\n",
    "        elif isinstance(d,list):\n",
    "            texts.append(\" \".join(all_texts(d)))\n",
    "        elif isinstance(d,str):\n",
    "            texts.append(d)\n",
    "        else:\n",
    "            try:\n",
    "                texts.append(str(d))\n",
    "            except:\n",
    "                raise Exception(f'type of d is {type(d)}')\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(all_texts(valid_dat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(all_texts(dat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(all_texts(test_dat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "625"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['ok']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the db model first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns_wi={'address': 5,\n",
    " 'agenda': 0,\n",
    " 'date': 6,\n",
    " 'distance': 8,\n",
    " 'event': 7,\n",
    " 'friday': 14,\n",
    " 'location': 2,\n",
    " 'monday': 10,\n",
    " 'party': 9,\n",
    " 'poi': 1,\n",
    " 'poi_type': 19,\n",
    " 'room': 15,\n",
    " 'saturday': 4,\n",
    " 'sunday': 12,\n",
    " 'thursday': 16,\n",
    " 'time': 17,\n",
    " 'today': 13,\n",
    " 'traffic_info': 11,\n",
    " 'tuesday': 3,\n",
    " 'wednesday': 18}\n",
    "\n",
    "all_columns = {int(v):w for w,v in all_columns_wi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all_columns\n",
    "assert tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_QUERIES = 1\n",
    "NUM_COL = len(all_columns)\n",
    "CONV_VOCAB_LEN = len(tokenizer.word_index)+1\n",
    "THRESHOLD = 0.5\n",
    "MAX_DB_RESULTS = 5\n",
    "MAX_ENTITY_LENGTH = 10\n",
    "OPERATOR_LEN = 6\n",
    "NUM_INTENTS = 3\n",
    "EMBEDDING_SIZE=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.zeros((5,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['poi', 'poi_type', 'address', 'distance', 'traffic_info']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting rules based db to desired output first\n",
    "def results_to_vector(bs_output,pred_intent,operation,kb_data,kb_intent,kb_columns):\n",
    "    assert bs_output.shape == (NUM_COL,MAX_ENTITY_LENGTH,CONV_VOCAB_LEN)\n",
    "    assert operation.shape == (NUM_COL,OPERATOR_LEN)\n",
    "    pred_intent = np.argmax(pred_intent) if max(pred_intent)>THRESHOLD else None\n",
    "    kb_intent = np.argmax(kb_intent)\n",
    "    output=np.zeros((MAX_DB_RESULTS,NUM_COL,MAX_ENTITY_LENGTH,CONV_VOCAB_LEN))\n",
    "    if intent is None:\n",
    "        return output\n",
    "    q=bs_output\n",
    "    op = operation\n",
    "    op_conf =  np.max(op,axis=-1)\n",
    "    op_classes = np.argmax(op,axis=-1) \n",
    "    op_classes = [_q if _q_conf>THRESHOLD else None for _q,_q_conf in zip(op_classes,op_conf)]\n",
    "\n",
    "    q_ents = np.argmax(q,axis=-1)\n",
    "    q_confs = np.max(q,axis=-1)\n",
    "    q_mask = np.array(q_confs>THRESHOLD,dtype='float32')\n",
    "    q_ents = q_mask*q_ents\n",
    "    q_words = [\" \".join([tokenizer.index_word[_q] for _q in __q if _q!=0]) for __q in q_ents]\n",
    "    # Now that q_words and op_classes are known\n",
    "    bs={}\n",
    "    operations = {}\n",
    "    for j,ent in enumerate(q_words):\n",
    "        if ent is None or ent==\"\": continue\n",
    "        bs[all_columns[j]]=ent\n",
    "        operations[all_columns[j]] = op_classes[j]\n",
    "    result,confidence = kb_results(kb_data,kb_intent,columns,pred_intent,bs,operations)\n",
    "    result=np.array(result)\n",
    "    confidence=np.array(confidence)\n",
    "    result = result[np.argsort(confidence)[-1::-1]]\n",
    "    confidence = confidence[np.argsort(confidence)[-1::-1]]\n",
    "    final_result=[kb_data[_i] for _i,(c,r) in enumerate(zip(confidence,result)) if c>=THRESHOLD and r==1]\n",
    "    confidence=[confidence[_i] for _i,(c,r) in enumerate(zip(confidence,result)) if c>=THRESHOLD and r==1]\n",
    "    kb_result = np.zeros((MAX_DB_RESULTS,NUM_COL,MAX_ENTITY_LENGTH,CONV_VOCAB_LEN))\n",
    "    for j,r in enumerate(final_result):\n",
    "        if j==MAX_DB_RESULTS: break\n",
    "        for k,v in r.items():\n",
    "            kb_result[j,all_columns_wi[k]] = to_categorical(pad_sequences(tokenizer.texts_to_sequences([v]),\n",
    "                                                            padding='post',truncating='post',maxlen=MAX_ENTITY_LENGTH)\\\n",
    "                                                             ,num_classes=CONV_VOCAB_LEN)*confidence[j]\n",
    "    output = kb_result\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_output=np.zeros((NUM_COL,MAX_ENTITY_LENGTH,CONV_VOCAB_LEN))\n",
    "intent=np.array([1,0,0])\n",
    "operation = np.zeros((NUM_COL,OPERATOR_LEN))\n",
    "bs_output[16,0:2]=to_categorical(tokenizer.texts_to_sequences(['6 miles'])[0],num_classes=CONV_VOCAB_LEN)\n",
    "operation[16,0]=1.0\n",
    "kb_data = dat[0]['scenario']['kb']['items']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-22-9a58e03dd849>(14)kb_results()\n",
      "-> if pred_kb_intent!=kb_intent:\n",
      "(Pdb) exit\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-967f24bd14be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresults_to_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mintent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moperation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkb_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkb_intent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-46-3b286811caf1>\u001b[0m in \u001b[0;36mresults_to_vector\u001b[0;34m(bs_output, pred_intent, operation, kb_data, kb_intent, kb_columns)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mbs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mall_columns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0moperations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mall_columns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop_classes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconfidence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkb_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkb_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkb_intent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred_intent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moperations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mresult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mconfidence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfidence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-9a58e03dd849>\u001b[0m in \u001b[0;36mkb_results\u001b[0;34m(kb_data, kb_intent, columns, pred_kb_intent, belief_state, operation)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mpred_kb_intent\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0mkb_intent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkb_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-9a58e03dd849>\u001b[0m in \u001b[0;36mkb_results\u001b[0;34m(kb_data, kb_intent, columns, pred_kb_intent, belief_state, operation)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mpred_kb_intent\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0mkb_intent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkb_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/miniconda3/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/miniconda3/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "r=results_to_vector(bs_output,intent,operation,kb_data,kb_intent,columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[np.max(r[0,2,i,1:])>0 for i in range((MAX_ENTITY_LENGTH))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input,Dense,LSTM,Embedding,TimeDistributed, RepeatVector, Concatenate,Reshape\n",
    "from keras.layers import Lambda\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 1, 20, 50)\n"
     ]
    }
   ],
   "source": [
    "# model for db\n",
    "bs_input = Input(shape=(MAX_QUERIES,NUM_COL,MAX_ENTITY_LENGTH,CONV_VOCAB_LEN))\n",
    "intent_input = Input(shape=(MAX_QUERIES,NUM_INTENTS,))\n",
    "operation_input = Input(shape=(MAX_QUERIES,NUM_COL,OPERATOR_LEN))\n",
    "\n",
    "bs_proc = TimeDistributed(TimeDistributed(TimeDistributed(Dense(50,activation='sigmoid'))))(bs_input)\n",
    "LSTM_bs_emb = TimeDistributed(TimeDistributed(LSTM(50,return_sequences=False,return_state=False)))(bs_proc)\n",
    "rep_intent_input = TimeDistributed(RepeatVector(NUM_COL))(intent_input)\n",
    "print(LSTM_bs_emb.shape)\n",
    "all_steps = Concatenate(axis=-1)([LSTM_bs_emb,operation_input,rep_intent_input])\n",
    "all_steps = Lambda(lambda x: tf.reshape(x,shape=(-1,MAX_QUERIES,NUM_COL*(50+OPERATOR_LEN+NUM_INTENTS))))(all_steps)\n",
    "encoder_lstm = Dense(50,activation='relu')(all_steps)\n",
    "encoder_lstm = TimeDistributed(RepeatVector(MAX_DB_RESULTS))(encoder_lstm)\n",
    "\n",
    "decoder_lstm1 = TimeDistributed(LSTM(50,return_sequences=True))(encoder_lstm)\n",
    "\n",
    "decoder_lstm1 = Dense(NUM_COL*50,activation='relu')(decoder_lstm1)\n",
    "decoder_lstm1 = Lambda(lambda x: tf.reshape(x,shape=(-1,MAX_QUERIES,MAX_DB_RESULTS,NUM_COL,50)))(decoder_lstm1)\n",
    "\n",
    "\n",
    "decoder_lstm2 = TimeDistributed(Lambda(lambda x: K.tile(K.expand_dims(x,axis=-2),[1,1,1,MAX_ENTITY_LENGTH,1])))(decoder_lstm1)\n",
    "decoder_lstm3 = TimeDistributed(TimeDistributed(TimeDistributed(LSTM(50,return_sequences=True))))(decoder_lstm2)\n",
    "\n",
    "out = TimeDistributed(TimeDistributed(TimeDistributed(TimeDistributed(Dense(CONV_VOCAB_LEN,activation='softmax')))))(decoder_lstm3)\n",
    "db_model = Model(inputs=[bs_input,intent_input,operation_input],outputs=[out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 1, 20, 10, 61 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistrib (None, 1, 20, 10, 50 309200      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 1, 3)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_5 (TimeDistrib (None, 1, 20, 50)    20200       time_distributed_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 1, 20, 6)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_6 (TimeDistrib (None, 1, 20, 3)     0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1, 20, 59)    0           time_distributed_5[0][0]         \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 time_distributed_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1, 1180)      0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1, 50)        59050       lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_7 (TimeDistrib (None, 1, 5, 50)     0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_8 (TimeDistrib (None, 1, 5, 50)     20200       time_distributed_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1, 5, 1000)   51000       time_distributed_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 1, 5, 20, 50) 0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_9 (TimeDistrib (None, 1, 5, 20, 10, 0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_12 (TimeDistri (None, 1, 5, 20, 10, 20200       time_distributed_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_16 (TimeDistri (None, 1, 5, 20, 10, 315333      time_distributed_12[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 795,183\n",
      "Trainable params: 795,183\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "db_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_model.compile(optimizer='adam',loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing training inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(w, t = 1.0):\n",
    "    e = np.exp(np.array(w) / t)\n",
    "    dist = e / np.sum(e)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intent': 'navigate'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat[0]['scenario']['task']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "nav_cols=['distance','traffic_info','poi_type','address','poi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "intents = ['schedule', 'weather', 'navigate']\n",
    "def input_generator(batch_size,data=dat):\n",
    "    batch_data1=[]\n",
    "    batch_data2=[]\n",
    "    batch_data3=[]\n",
    "    target=[]\n",
    "    random_dat = [data[i] for i in np.random.permutation(len(data))]\n",
    "    ij=0\n",
    "    while True:\n",
    "        ij+=1\n",
    "        for d in random_dat:\n",
    "            kb_intent = d['scenario']['task']['intent']\n",
    "            if kb_intent!='navigate': continue\n",
    "            kb_col_names = d['scenario']['kb']['column_names']\n",
    "            kb_data = d['scenario']['kb']['items']\n",
    "            true_vec_intent = np.zeros(NUM_INTENTS)\n",
    "            true_vec_intent[intents.index(kb_intent)]=1.0\n",
    "            pred_intent = np.array([0,0,1])#softmax(np.random.normal(size=NUM_INTENTS,loc=100,scale=5))\n",
    "            bs_input = np.zeros((NUM_COL,MAX_ENTITY_LENGTH,CONV_VOCAB_LEN))\n",
    "            operation = np.zeros((NUM_COL,OPERATOR_LEN))\n",
    "            num_cols_to_have = np.random.randint(NUM_COL)+1\n",
    "            num_ents_to_have = [np.random.randint(MAX_ENTITY_LENGTH)+1 for _ in range(num_cols_to_have)]\n",
    "            for ii in range(num_cols_to_have):\n",
    "                col_idx = all_columns_wi[nav_cols[np.random.randint(5)]]\n",
    "                for j in range(num_ents_to_have[ii]):\n",
    "                    ix=(col_idx,j)\n",
    "                    bs_input[ix] = softmax(np.random.normal(size=CONV_VOCAB_LEN,loc=100,scale=5))\n",
    "                operation[col_idx] = softmax(np.random.normal(size=OPERATOR_LEN,loc=100,scale=5))\n",
    "\n",
    "            batch_data1.append([bs_input])\n",
    "            batch_data2.append([operation])\n",
    "            batch_data3.append([pred_intent])\n",
    "            target.append([results_to_vector(bs_input,pred_intent,operation,kb_data,true_vec_intent,kb_col_names)])\n",
    "            \n",
    "            if len(batch_data1)==batch_size:\n",
    "                yield [np.array(batch_data1),np.array(batch_data3),np.array(batch_data2)],np.array(target)\n",
    "                batch_data1=[]\n",
    "                batch_data2=[]\n",
    "                batch_data3=[]\n",
    "                target=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 172, 1464, 1134, 2143, 2887, 6055,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(sett[0][0][0,0,5,:,:],axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1=next(input_generator(1,dat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "def memory_exhausted():\n",
    "    if memory_percent_available()<=10:\n",
    "        print(\"Memory Exhausted\")\n",
    "        exit()\n",
    "class memCall(keras.callbacks.Callback):\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        memory_exhausted()\n",
    "        \n",
    "def memory_percent_available():\n",
    "    return psutil.virtual_memory().available/psutil.virtual_memory().total*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint=keras.callbacks.ModelCheckpoint('./tmp.h5',save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size=4\n",
    "db_model.fit_generator(input_generator(batch_size),validation_data=input_generator(batch_size,valid_dat),steps_per_epoch=100,epochs=10,validation_steps=50,callbacks=[memCall(),checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing db_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_model.load_weights('./src/db_model_G.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size=1\n",
    "db_model.evaluate_generator(input_generator(batch_size,valid_dat),steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kb_data = dat[22]['scenario']['kb']['items']\n",
    "kb_intent = dat[22]['scenario']['task']['intent']\n",
    "columns = dat[22]['scenario']['kb']['column_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_kb_intent = kb_intent\n",
    "belief_state = {'traffic_info':'no traffic','distance':'6 miles'}\n",
    "operation = {'traffic_info':0,'distance':2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "belief_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kb_results(kb_data,kb_intent,columns,pred_kb_intent,belief_state,operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenizer.texts_to_sequences(['no traffic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_columns_wi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_output=np.zeros((NUM_COL,MAX_ENTITY_LENGTH,CONV_VOCAB_LEN))\n",
    "intent=np.array([0,0,1])\n",
    "operation = np.zeros((NUM_COL,OPERATOR_LEN))\n",
    "bs_output[8,0:2]=to_categorical(tokenizer.texts_to_sequences(['6 miles'])[0],num_classes=CONV_VOCAB_LEN)\n",
    "operation[8] = np.array([1,0,0,0,0,0])\n",
    "kb_data = dat[0]['scenario']['kb']['items']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act=results_to_vector(bs_output,intent,operation,kb_data,intent,columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=db_model.predict([np.array([[bs_output]]),np.array([[intent]]),np.array([[operation]])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while(True):\n",
    "    sett=next(input_generator(batch_size=1))\n",
    "    if np.max(sett[1])==1:\n",
    "        break\n",
    "    pred=db_model.predict(sett[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kb_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(pred[0][0][0][0],axis=-1),np.max(pred[0][0][0][0][0],axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.index_word[13+7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sett[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.max(sett[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sett[1][0][0][0,5,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(sett[1][0][0][0,8,:,:],axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.index_word[103]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(pred[0][0][0,8,:,1:],axis=-1),np.argmax(pred[0][0][0,8,:,:],axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.argmax(pred[0][0],axis=-1),np.max(pred[0][0][0],axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(act[0],axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1=next(input_generator(1,dat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(a1[0][0][0][0][0][-1]),np.max(a1[0][0][0][0][0][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pympler import muppy\n",
    "from pympler import summary\n",
    "all_objects = muppy.get_objects()\n",
    "sum1 = summary.summarize(all_objects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_memory_usage(batch_size, model):\n",
    "    import numpy as np\n",
    "    from keras import backend as K\n",
    "\n",
    "    shapes_mem_count = 0\n",
    "    for l in model.layers:\n",
    "        single_layer_mem = 1\n",
    "        for s in l.output_shape:\n",
    "            if s is None:\n",
    "                continue\n",
    "            single_layer_mem *= s\n",
    "        shapes_mem_count += single_layer_mem\n",
    "\n",
    "    trainable_count = np.sum([K.count_params(p) for p in set(model.trainable_weights)])\n",
    "    non_trainable_count = np.sum([K.count_params(p) for p in set(model.non_trainable_weights)])\n",
    "\n",
    "    total_memory = 4.0*batch_size*(shapes_mem_count + trainable_count + non_trainable_count)\n",
    "    gbytes = np.round(total_memory / (1024.0 ** 3), 3)\n",
    "    return gbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_model_memory_usage(16,db_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pympler import asizeof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asizeof.asizeof(a1)/1024/1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asizeof.asizeof(db_model.layers[0])/1024/1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the complete model now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model would receive the belief states and give out the sentences in the coeherent form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 30\n",
    "LATENT_DIM = 50\n",
    "CONV_VOCAB_LEN = 30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.engine.network import Network\n",
    "def get_model(db_m):\n",
    "    frozen_db_m = Network(db_m.input,db_m.output,name='frozen_db_model')\n",
    "    \n",
    "    text_in = Input(shape=(MAX_SEQ_LEN,EMBEDDING_SIZE))\n",
    "    text_tok_in = Input(shape=(MAX_SEQ_LEN,CONV_VOCAB_LEN))\n",
    "    emb_state_in_h = Input(shape=(LATENT_DIM,))\n",
    "    emb_state_in_c = Input(shape=(LATENT_DIM,))\n",
    "    \n",
    "    encoding,emb_state_out_h,emb_state_out_c = LSTM(LATENT_DIM,\\\n",
    "                                                    return_state=True)(text_in,\\\n",
    "                                            initial_state=[emb_state_in_h,emb_state_in_c])\n",
    "    \n",
    "    \n",
    "    \n",
    "    db_decoder_1 = Lambda(lambda x: K.tile(K.expand_dims(x,axis=-2),[1,MAX_QUERIES,1]))(encoding)\n",
    "    db_decoder_2 = LSTM(NUM_COL*LATENT_DIM,return_sequences=True)(db_decoder_1)\n",
    "    db_decoder_2 = Lambda(lambda x: tf.reshape(x,[-1,MAX_QUERIES,NUM_COL,LATENT_DIM]))(db_decoder_2)\n",
    "    \n",
    "    db_decoder_3 = Lambda(lambda x: K.tile(K.expand_dims(x,axis=-2),[1,1,1,MAX_ENTITY_LENGTH,1]))(db_decoder_2)\n",
    "    db = TimeDistributed(TimeDistributed(LSTM(LATENT_DIM,return_sequences=True)))(db_decoder_3)\n",
    "    bs_out = Dense(MAX_SEQ_LEN,activation='softmax')(db)\n",
    "    text_tok_in_reshape = Lambda(lambda x: tf.reshape(x,[-1,1,1,1,MAX_SEQ_LEN,CONV_VOCAB_LEN]))(text_tok_in)\n",
    "    \n",
    "    bs_out = Lambda(lambda x: K.expand_dims(x))(bs_out)\n",
    "    print(bs_out.shape,text_tok_in_reshape.shape)\n",
    "    bs_out = Lambda(lambda x: tf.reduce_sum(x[0]*x[1],axis=-2))([bs_out,text_tok_in])\n",
    "    print(bs_out.shape)\n",
    "    op_out = Dense(LATENT_DIM,activation='relu')(db_decoder_2)\n",
    "    op_out = Dense(OPERATOR_LEN,activation='softmax')(op_out)\n",
    "    print(op_out.shape)\n",
    "    intent_out = Dense(LATENT_DIM,activation='relu')(encoding)\n",
    "    intent_out = Dense(NUM_INTENTS,activation='softmax')(intent_out)\n",
    "    intent_out = RepeatVector(MAX_QUERIES)(intent_out)\n",
    "    model_bs = Model(inputs=[text_in,emb_state_in_h,emb_state_in_c,text_tok_in],outputs=[bs_out,intent_out,op_out])\n",
    "    # DECODER\n",
    "    print(bs_out,intent_out,op_out)\n",
    "    decoder_input_db = frozen_db_m([bs_out,intent_out,op_out])\n",
    "    other_bs_input = encoding\n",
    "    \n",
    "    #Mdecoder_input_b is of length None,MAX_QUERIES,MAX_DB_RESULTS,NUM_COL,MAX_ENTITY_LENGTH,CONV_VOCAB_LEN\n",
    "    dbout_encoder_maxent = TimeDistributed(TimeDistributed(TimeDistributed(LSTM(LATENT_DIM))))(decoder_input_db)\n",
    "    dbout_encoder_ncol =  Lambda(lambda x: tf.reshape(x,[-1,MAX_QUERIES,MAX_DB_RESULTS,NUM_COL*LATENT_DIM]))(dbout_encoder_maxent)\n",
    "    dbout_encoder_ncol = Dense(LATENT_DIM,activation='relu')(dbout_encoder_ncol)\n",
    "    dbout_encoder_dbr = TimeDistributed(LSTM(LATENT_DIM))(dbout_encoder_ncol)\n",
    "    other_bs_input_rep = RepeatVector(MAX_QUERIES)(other_bs_input)\n",
    "    dbout_encoder = Concatenate(axis=-1)([dbout_encoder_dbr,other_bs_input_rep])\n",
    "    _,dbout_s,dbout_h = LSTM(LATENT_DIM,return_state=True)(dbout_encoder)\n",
    "    decoder_hidden_inputs = [dbout_s,dbout_h]\n",
    "    \n",
    "    decoder_inputs = Input(shape=(MAX_SEQ_LEN,EMBEDDING_SIZE))\n",
    "    print(decoder_inputs.shape,decoder_hidden_inputs[0].shape,decoder_hidden_inputs[1].shape)\n",
    "    decoder_LSTM = LSTM(LATENT_DIM,return_sequences=True,return_state=True)\n",
    "    decoder_outputs,_,_ = decoder_LSTM(decoder_inputs,initial_state=decoder_hidden_inputs)\n",
    "    decoder_outputs = Dense(CONV_VOCAB_LEN,activation='softmax')(decoder_outputs)\n",
    "    \n",
    "    full_model = Model(inputs=[text_in,emb_state_in_h,emb_state_in_c,text_tok_in,decoder_inputs],outputs=[decoder_outputs])\n",
    "    full_model.compile(loss='categorical_crossentropy',optimizer='adam')\n",
    "    return full_model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model=get_model(db_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input((10,vocab_len))\n",
    "encoder = LSTM(50,return_state=True)\n",
    "out,out_h,out_c=encoder(inp)\n",
    "out = Dense(vocab_len,activation='softmax')(out)\n",
    "model_rnn_2=Model(inputs=[inp],outputs=out)\n",
    "\n",
    "out_3 = frozen_db_model(model_rnn_2.output)\n",
    "out_35 = RepeatVector(10)(out_3)\n",
    "decoder = LSTM(50,return_sequences=True,return_state=True)\n",
    "out_4,_,_= decoder(out_35,initial_state=[out_h,out_c])\n",
    "out_4 = Dense(vocab_len,activation='softmax')(out_4)\n",
    "model_4 = Model(inputs=[model_rnn_2.input],outputs=[model_rnn_2.output,out_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
