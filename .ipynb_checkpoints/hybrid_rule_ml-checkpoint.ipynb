{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [\"what is <> doing?\",\"what is being done by <>?\",\"<> is upto what?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"john\",\"aman\",\"aparna\",\"dog\",\"amit\",\"ketan\"]\n",
    "actions = [\"dancing\",\"playing\",\"singing\",\"skating\",\"riding\",\"climbing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "Y=[]\n",
    "N=[]\n",
    "def gen_sent(inputs,names,actions):\n",
    "    for n in names:\n",
    "        for ii in range(len(inputs)*100):\n",
    "            i = inputs[ii%len(inputs)]\n",
    "            X.append(re.sub(r'<>',n,i))\n",
    "            num=np.random.randint(len(actions)*100)\n",
    "            Y.append(n+' is '+actions[num%len(actions)])\n",
    "            N.append(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_sent(inputs,names,actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/miniconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/usr/lib/miniconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/miniconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer,one_hot\n",
    "from keras.models import Model\n",
    "from keras.layers import Input,Dense\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.fit_on_texts(X)\n",
    "t.fit_on_texts(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.index_word = {i:w for w,i in t.word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_len=len(t.word_index.keys())+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelling the db\n",
    "m_in = Input(shape=(vocab_len,))\n",
    "m = Dense(vocab_len,activation='sigmoid')(m_in)\n",
    "db_model = Model(inputs=[m_in],outputs=[m])\n",
    "db_model.compile(loss='binary_crossentropy',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(w, t = 1.0):\n",
    "    e = np.exp(np.array(w) / t)\n",
    "    dist = e / np.sum(e)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8915433879323535"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(softmax(np.random.normal(size=vocab_len,loc=100,scale=5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "db_X = []\n",
    "db_Y = []\n",
    "for _ in range(1000):\n",
    "    vec = softmax(np.random.normal(size=vocab_len,loc=100,scale=5))\n",
    "    v= t.index_word[np.argmax(vec)] if np.max(vec)>0.5 and np.argmax(vec)!=0 else ''\n",
    "    for _ in range(100):\n",
    "        db_X.append(vec)\n",
    "        if v not in names:\n",
    "            db_Y.append(np.array([0  for ii in range(vocab_len)]))\n",
    "            continue\n",
    "        num=np.random.randint(len(actions))\n",
    "        ix = t.word_index[actions[num]]\n",
    "        db_Y.append(np.array(to_categorical([ix],num_classes=vocab_len))[0])\n",
    "dist=np.random.permutation(len(db_X))\n",
    "db_Y = np.array(db_Y)[dist]\n",
    "db_X = np.array(db_X)[dist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "db_model.fit(np.array(db_X),np.array(db_Y),epochs=100*2,validation_split=0.2,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 889,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 889,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_categorical(t.texts_to_sequences([\"Aman what doing\"]),num_classes=vocab_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 890,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=db_model.predict(to_categorical(t.texts_to_sequences([\"Aman what doing\"]),num_classes=vocab_len)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 891,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  3, 12, 10, 11,  9,  0,  5,  8,  4, 13,  7,  6,  2, 17, 18,\n",
       "        19, 15, 14, 16],\n",
       "       [ 9,  2,  3,  8,  4, 10, 11, 12,  5,  7,  6,  1,  0, 13, 19, 14,\n",
       "        17, 16, 18, 15],\n",
       "       [ 5,  0,  3, 13,  7,  9,  8, 12, 11, 10,  1,  2,  4,  6, 18, 19,\n",
       "        15, 17, 16, 14]])"
      ]
     },
     "execution_count": 891,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.argsort(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 892,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 13, 12, 11, 10,  8,  7,  9,  5,  4,  3,  2,  1,  6, 15, 17, 19,\n",
       "       16, 14, 18])"
      ]
     },
     "execution_count": 892,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(np.sum(db_Y,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('is', 5.1372255e-05),\n",
       "  ('john', 5.3506534e-05),\n",
       "  ('amit', 5.583091e-05),\n",
       "  ('aparna', 5.623037e-05),\n",
       "  ('dog', 5.6525954e-05),\n",
       "  ('aman', 5.7528854e-05),\n",
       "  ('null', 5.7722504e-05),\n",
       "  ('being', 5.8468693e-05),\n",
       "  ('upto', 6.0989365e-05),\n",
       "  ('doing', 6.619377e-05),\n",
       "  ('ketan', 7.074403e-05),\n",
       "  ('by', 7.46354e-05),\n",
       "  ('done', 8.182025e-05),\n",
       "  ('what', 8.33949e-05),\n",
       "  ('singing', 0.2276803),\n",
       "  ('skating', 0.2288896),\n",
       "  ('dancing', 0.23287329),\n",
       "  ('riding', 0.23636907),\n",
       "  ('climbing', 0.24567087),\n",
       "  ('playing', 0.26192605)],\n",
       " [('aman', 5.2855263e-05),\n",
       "  ('what', 5.518239e-05),\n",
       "  ('john', 6.0049657e-05),\n",
       "  ('upto', 6.651908e-05),\n",
       "  ('doing', 6.8830974e-05),\n",
       "  ('aparna', 6.8895584e-05),\n",
       "  ('dog', 7.321454e-05),\n",
       "  ('amit', 7.325351e-05),\n",
       "  ('being', 8.166716e-05),\n",
       "  ('by', 8.305974e-05),\n",
       "  ('done', 8.8601424e-05),\n",
       "  ('is', 9.0596724e-05),\n",
       "  ('null', 9.9301666e-05),\n",
       "  ('ketan', 9.964095e-05),\n",
       "  ('dancing', 0.0019445932),\n",
       "  ('climbing', 0.0019566594),\n",
       "  ('singing', 0.0020150975),\n",
       "  ('playing', 0.0026246193),\n",
       "  ('skating', 0.0026602787),\n",
       "  ('riding', 0.0027270906)],\n",
       " [('being', 5.232527e-05),\n",
       "  ('null', 5.2541072e-05),\n",
       "  ('john', 5.353113e-05),\n",
       "  ('ketan', 5.9154423e-05),\n",
       "  ('by', 7.313402e-05),\n",
       "  ('aman', 7.5537726e-05),\n",
       "  ('upto', 7.641328e-05),\n",
       "  ('amit', 7.648509e-05),\n",
       "  ('dog', 8.021045e-05),\n",
       "  ('aparna', 8.218183e-05),\n",
       "  ('is', 8.280501e-05),\n",
       "  ('what', 8.367419e-05),\n",
       "  ('doing', 8.763527e-05),\n",
       "  ('done', 8.83372e-05),\n",
       "  ('skating', 0.0007377157),\n",
       "  ('dancing', 0.0008398692),\n",
       "  ('riding', 0.00086574047),\n",
       "  ('singing', 0.00089173485),\n",
       "  ('playing', 0.0009943576),\n",
       "  ('climbing', 0.0010073358)]]"
      ]
     },
     "execution_count": 893,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[(t.index_word[i],_j[i]) if i!=0 else ('null',_j[i]) for i in j] for j,_j in zip(y.argsort(axis=-1),y) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=db_model.predict(np.array([[0,0,0,0.9]+[0]*16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 918,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('what', 8.408155e-05),\n",
       "  ('null', 8.413007e-05),\n",
       "  ('being', 8.45112e-05),\n",
       "  ('doing', 8.5696935e-05),\n",
       "  ('done', 8.6287924e-05),\n",
       "  ('john', 8.741376e-05),\n",
       "  ('aparna', 9.202925e-05),\n",
       "  ('dog', 9.265268e-05),\n",
       "  ('ketan', 0.000104132865),\n",
       "  ('upto', 0.00012151976),\n",
       "  ('by', 0.00012472768),\n",
       "  ('amit', 0.00012680521),\n",
       "  ('is', 0.00013283531),\n",
       "  ('aman', 0.00014400162),\n",
       "  ('dancing', 0.19198023),\n",
       "  ('singing', 0.19848178),\n",
       "  ('skating', 0.20987819),\n",
       "  ('riding', 0.21131034),\n",
       "  ('playing', 0.2150975),\n",
       "  ('climbing', 0.21973051)]]"
      ]
     },
     "execution_count": 918,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[(t.index_word[i],_j[i]) if i!=0 else ('null',_j[i]) for i in j] for j,_j in zip(y.argsort(axis=-1),y) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 921,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 922,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input((5,vocab_len))\n",
    "out = SimpleRNN(vocab_len,activation='sigmoid')(inp)\n",
    "model_rnn=Model(inputs=[inp],outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 925,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "out = db_model(model_rnn.output)\n",
    "model = Model(inputs=[model_rnn.input],outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 929,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_33 (InputLayer)        (None, 5, 20)             0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 20)                820       \n",
      "_________________________________________________________________\n",
      "model_30 (Model)             (None, 20)                420       \n",
      "=================================================================\n",
      "Total params: 1,240\n",
      "Trainable params: 1,240\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "model.layers[-1].trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 931,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_model.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
