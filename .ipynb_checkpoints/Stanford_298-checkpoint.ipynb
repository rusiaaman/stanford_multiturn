{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/miniconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/usr/lib/miniconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/miniconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='./kvret_dataset_public/'\n",
    "with open(path+'kvret_train_public.json') as f:\n",
    "    dat=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path+'kvret_dev_public.json') as f:\n",
    "    valid_dat=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path+'kvret_test_public.json') as f:\n",
    "    test_dat=json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "dic = defaultdict(str)\n",
    "for d in dat:\n",
    "    for _d in d['dialogue']:\n",
    "        dic.update(_d['data'].get('slots',{}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "dic = set([])\n",
    "for d in dat:\n",
    "    for _d in d['dialogue']:\n",
    "        slots = _d['data'].get('slots')\n",
    "        if not slots: continue\n",
    "        dic.update([slots.get('distance')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "dic = defaultdict(str)\n",
    "for d in dat:\n",
    "    for _d in d['dialogue']:\n",
    "        dic.update(_d.get('data',{}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "requested_slots = list(dic['requested'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['kb', 'task', 'uuid'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['scenario'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'location', 'thursday', 'traffic_info', 'address', 'room', 'party', 'wednesday', 'saturday', 'sunday', 'today', 'friday', 'event', 'time', 'distance', 'date', 'poi', 'monday', 'tuesday', 'poi_type', 'agenda'}\n"
     ]
    }
   ],
   "source": [
    "s=set([])\n",
    "for d in dat:\n",
    "    try:\n",
    "        keys=d['scenario']['kb']['column_names']\n",
    "    except:\n",
    "        continue\n",
    "    s.update(keys)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'moderate traffic', 'heavy traffic', 'car collision nearby', 'no traffic', 'road block nearby'}\n"
     ]
    }
   ],
   "source": [
    "s=set([])\n",
    "for d in dat:\n",
    "    try:\n",
    "        keys=[t['traffic_info'] for t in d['scenario']['kb']['items'] ]\n",
    "    except:\n",
    "        continue\n",
    "    s.update(keys)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'location information', 'weekly forecast', 'calendar'}\n"
     ]
    }
   ],
   "source": [
    "s=set([])\n",
    "for d in dat:\n",
    "    try:\n",
    "        keys=[d['scenario']['kb']['kb_title']]\n",
    "    except:\n",
    "        continue\n",
    "    s.update(keys)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'schedule', 'navigate', 'weather'}\n"
     ]
    }
   ],
   "source": [
    "s=set([])\n",
    "for d in dat:\n",
    "    try:\n",
    "        keys=[d['scenario']['task']['intent']]\n",
    "    except:\n",
    "        print(d)\n",
    "        continue\n",
    "    s.update(keys)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'set'>, {'location information': {'navigate'}, 'calendar': {'schedule'}, 'weekly forecast': {'weather'}})\n"
     ]
    }
   ],
   "source": [
    "s=defaultdict(set)\n",
    "for d in dat:\n",
    "    try:\n",
    "        s[d['scenario']['kb']['kb_title']].update([d['scenario']['task']['intent']])\n",
    "    except:\n",
    "        print(d)\n",
    "        continue\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'set'>, {'navigate': {'traffic_info', 'address', 'distance', 'poi', 'poi_type'}, 'schedule': {'room', 'party', 'date', 'event', 'time', 'agenda'}, 'weather': {'location', 'thursday', 'wednesday', 'saturday', 'today', 'friday', 'monday', 'tuesday', 'sunday'}})\n"
     ]
    }
   ],
   "source": [
    "s=defaultdict(set)\n",
    "for d in dat:\n",
    "    try:\n",
    "        s[d['scenario']['task']['intent']].update(d['scenario']['kb']['column_names'])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dialogue': [{'turn': 'driver', 'data': {'end_dialogue': False, 'utterance': 'check forecast for new york'}}, {'turn': 'assistant', 'data': {'end_dialogue': False, 'requested': {'weather_attribute': True, 'date': False, 'location': True}, 'slots': {'location': ' new york'}, 'utterance': 'The weather this week will be hail and rain on Thursday and Sunday, with the lowest temperature being 20F and the highest 90F, Monday will be the only hot day. '}}, {'turn': 'driver', 'data': {'end_dialogue': False, 'utterance': 'Will it be overcast on friday?'}}, {'turn': 'assistant', 'data': {'end_dialogue': False, 'requested': {'weather_attribute': True, 'date': True, 'location': False}, 'slots': {'weather_attribute': 'overcast', 'date': 'Friday'}, 'utterance': 'On Friday it will be cloudy on New York'}}, {'turn': 'driver', 'data': {'end_dialogue': False, 'utterance': 'Thank you!'}}, {'turn': 'assistant', 'data': {'end_dialogue': True, 'requested': {'weather_attribute': False, 'date': False, 'location': False}, 'slots': {}, 'utterance': \"You're welcome!\"}}], 'scenario': {'kb': {'items': [{'monday': 'stormy, low of 50F, high of 70F', 'tuesday': 'cloudy, low of 20F, high of 40F', 'friday': 'windy, low of 20F, high of 40F', 'wednesday': 'clear skies, low of 50F, high of 60F', 'thursday': 'stormy, low of 50F, high of 70F', 'sunday': 'hail, low of 30F, high of 50F', 'location': 'manhattan', 'saturday': 'snow, low of 60F, high of 70F', 'today': 'monday'}, {'monday': 'overcast, low of 50F, high of 70F', 'tuesday': 'stormy, low of 90F, high of 100F', 'friday': 'clear skies, low of 70F, high of 80F', 'wednesday': 'frost, low of 50F, high of 60F', 'thursday': 'snow, low of 80F, high of 90F', 'sunday': 'dry, low of 70F, high of 80F', 'location': 'camarillo', 'saturday': 'blizzard, low of 40F, high of 50F', 'today': 'monday'}, {'monday': 'dry, low of 50F, high of 70F', 'tuesday': 'warm, low of 80F, high of 90F', 'friday': 'cloudy, low of 70F, high of 80F', 'wednesday': 'hail, low of 20F, high of 40F', 'thursday': 'blizzard, low of 40F, high of 60F', 'sunday': 'stormy, low of 90F, high of 100F', 'location': 'menlo park', 'saturday': 'foggy, low of 50F, high of 60F', 'today': 'monday'}, {'monday': 'hot, low of 70F, high of 90F', 'tuesday': 'foggy, low of 70F, high of 90F', 'friday': 'cloudy, low of 70F, high of 90F', 'wednesday': 'dry, low of 40F, high of 50F', 'thursday': 'hail, low of 40F, high of 50F', 'sunday': 'rain, low of 20F, high of 30F', 'location': 'new york', 'saturday': 'clear skies, low of 70F, high of 90F', 'today': 'monday'}, {'monday': 'windy, low of 70F, high of 80F', 'tuesday': 'overcast, low of 40F, high of 50F', 'friday': 'hail, low of 60F, high of 70F', 'wednesday': 'hail, low of 90F, high of 100F', 'thursday': 'rain, low of 80F, high of 100F', 'sunday': 'frost, low of 20F, high of 30F', 'location': 'corona', 'saturday': 'warm, low of 60F, high of 80F', 'today': 'monday'}, {'monday': 'cloudy, low of 90F, high of 100F', 'tuesday': 'dry, low of 30F, high of 40F', 'friday': 'foggy, low of 20F, high of 30F', 'wednesday': 'stormy, low of 80F, high of 100F', 'thursday': 'snow, low of 20F, high of 30F', 'sunday': 'drizzle, low of 50F, high of 60F', 'location': 'seattle', 'saturday': 'drizzle, low of 40F, high of 60F', 'today': 'monday'}, {'monday': 'drizzle, low of 70F, high of 80F', 'tuesday': 'overcast, low of 40F, high of 60F', 'friday': 'foggy, low of 50F, high of 60F', 'wednesday': 'overcast, low of 60F, high of 80F', 'thursday': 'snow, low of 20F, high of 40F', 'sunday': 'cloudy, low of 30F, high of 40F', 'location': 'grand rapids', 'saturday': 'dry, low of 90F, high of 100F', 'today': 'monday'}], 'column_names': ['location', 'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday', 'today'], 'kb_title': 'weekly forecast'}, 'task': {'intent': 'weather'}, 'uuid': '89cae425-6ff7-48b4-8b42-ec50b541dc63'}}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "defaultdict(<class 'set'>, {})\n"
     ]
    }
   ],
   "source": [
    "s=defaultdict(set)\n",
    "for d in dat:\n",
    "    try:\n",
    "        if d['scenario']['task']['intent'] == 'weather':\n",
    "            print(d)\n",
    "            print('\\n\\n\\n\\n')\n",
    "            break\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KB results with beilef states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'str'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "defaultdict(lambda: 'str')['hi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "def sim(a, b):\n",
    "    return SequenceMatcher(None, a.lower(), b.lower()).ratio()\n",
    "\n",
    "def close(a,b):\n",
    "    return sim(a,b)>=0.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import dateutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_op(s1,op,s2):\n",
    "    if isinstance(s1, (int, float)):\n",
    "        num1 = s1\n",
    "    else:\n",
    "        m1=re.search(r'([0-9]+)',s1)\n",
    "        if m1 is None:\n",
    "            try:\n",
    "                num1=dateutil.parser.parse(s1)\n",
    "            except ValueError:\n",
    "                return False,None\n",
    "        num1=int(m1.group())\n",
    "           \n",
    "    if isinstance(s2,(int,float)):\n",
    "        num2 = s2\n",
    "    else:\n",
    "        m2=re.search(r'([0-9]+)',s2)\n",
    "        if m2 is None:\n",
    "            try:\n",
    "                num2=dateutil.parser.parse(s2)\n",
    "            except ValueError:\n",
    "                return False ,None     \n",
    "        num2=int(m2.group())\n",
    "    try:\n",
    "        if op=='equal to':\n",
    "            return num1==num2,num1\n",
    "        if op=='greater than':\n",
    "            return num1>num2,num1\n",
    "        if op=='less than':\n",
    "            return num1<num2,num1\n",
    "    except TypeError:\n",
    "        return False,num1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kb_results(kb_data,kb_intent,columns,pred_kb_intent,belief_state,operation):\n",
    "    \"\"\"This function gets the kb_data, column names and intent for which the kb is received. \n",
    "    If intent identified by the bot is nto same as kb_intent no results will be returned.\n",
    "    \n",
    "    intents types: {'schedule', 'weather', 'navigate'}\n",
    "    \n",
    "    operation should have same keys as belief state with following possible values:\n",
    "    str, =, >, <, minimum, maximum  indexed from 0 to 5\n",
    "    Use None for all the values not numerical. If not None, operation would be performend\n",
    "    \"\"\"\n",
    "    #defaultdict(<class 'set'>, {'navigate': {'poi', 'distance', 'poi_type', 'traffic_info', 'address'},, 'weather': {'thursday', 'sunday', 'today', 'friday', 'wednesday', 'tuesday', 'saturday', 'location', 'monday'}})\n",
    "    if pred_kb_intent!=kb_intent:\n",
    "        return [],[]\n",
    "    if kb_data is None:\n",
    "        return [],[]\n",
    "    results = np.ones(len(kb_data))\n",
    "    confidence = np.ones(len(kb_data))\n",
    "    # column names possiblity: {'room', 'party', 'event', 'agenda', 'date', 'time'}  \n",
    "    # Note that date and time are immutable and non-comparable in current dialog, so they are treated as strings\n",
    "    col_types = defaultdict(lambda: 'str')\n",
    "    if any(k not in columns for k in belief_state.keys()):\n",
    "        return [],[]\n",
    "    for k in belief_state.keys():\n",
    "        min_idx = None\n",
    "        min_val = float('Inf')\n",
    "        max_idx = None\n",
    "        max_val = -float('Inf')\n",
    "        for i,items in enumerate(kb_data):\n",
    "            if results[i] == 0: continue\n",
    "            if col_types[k]=='str':\n",
    "                if not (belief_state.get(k) and items.get(k) and operation.get(k) is not None):\n",
    "                    results[i]=0\n",
    "                    confidence[i]=0\n",
    "                else:\n",
    "                    results[i]=0\n",
    "                    if operation[k]==0 and close(belief_state[k],items[k]):\n",
    "                        # Doing string comparison\n",
    "                        results[i]=1\n",
    "                        confidence[i] = confidence[i]*sim(belief_state.get(k),items.get(k))\n",
    "                    elif operation[k]==1:\n",
    "                        #Doing equal comparison extracting the first number\n",
    "                        if num_op(belief_state[k],'equal to',items[k])[0]:\n",
    "                            results[i]=1\n",
    "                    elif operation[k]==2:\n",
    "                        #Doing greater than comparison extracting the first number\n",
    "                        if num_op(belief_state[k],'less than',items[k])[0]:\n",
    "                            results[i]=1\n",
    "                    elif operation[k]==3:\n",
    "                        #Doing less than comparison extracting the first number\n",
    "                        if num_op(belief_state[k],'greater than',items[k])[0]:\n",
    "                            results[i]=1\n",
    "                    elif operation[k]==4:\n",
    "                        #Doing mimum comparison extracting the first number\n",
    "                        res,val = num_op(items[k],'less than',(min_val))\n",
    "                        if res:\n",
    "                            results[i]=1\n",
    "                            if min_idx is not None:\n",
    "                                results[min_idx] = 0\n",
    "                                confidence[min_idx] = 0\n",
    "                            min_val = val\n",
    "                            min_idx = i\n",
    "                    elif operation[k]==5:\n",
    "                        #Doing maximum comparison extracting the first number\n",
    "                        res,val = num_op(items[k],'greater than',(max_val))\n",
    "                        if res:\n",
    "                            results[i]=1\n",
    "                            if max_idx is not None:\n",
    "                                results[max_idx] = 0\n",
    "                                confidence[max_idx] = 0\n",
    "                            max_val = val\n",
    "                            max_idx = i\n",
    "    \n",
    "           \n",
    "    return np.array(results),np.array(confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "kb_data = dat[22]['scenario']['kb']['items']\n",
    "kb_intent = dat[22]['scenario']['task']['intent']\n",
    "columns = dat[22]['scenario']['kb']['column_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_kb_intent = kb_intent\n",
    "belief_state = {'traffic_info':'no traffic','distance':'6 miles'}\n",
    "operation = {'traffic_info':0,'distance':5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 0., 0., 0., 0., 1., 0.]),\n",
       " array([0.        , 1.        , 0.        , 1.        , 0.69230769,\n",
       "        1.        , 0.69565217, 1.        ]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kb_results(kb_data,kb_intent,columns,pred_kb_intent,belief_state,operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'distance': '1 miles',\n",
       " 'traffic_info': 'no traffic',\n",
       " 'poi_type': 'chinese restaurant',\n",
       " 'address': '271 Springer Street',\n",
       " 'poi': 'Mandarin Roots'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kb_data[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from tqdm import tqdm\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(t):\n",
    "    return word_tokenize(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2425/2425 [00:00<00:00, 99260.15it/s]\n"
     ]
    }
   ],
   "source": [
    "# collection of kb documents\n",
    "doc_kb=[]\n",
    "for d in tqdm(dat):\n",
    "    try:\n",
    "        for item in d['scenario']['kb']['items']:\n",
    "            [doc_kb.append(t)  for t in item.values()]\n",
    "    except TypeError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2425/2425 [00:00<00:00, 292569.75it/s]\n"
     ]
    }
   ],
   "source": [
    "doc_colnames=[]\n",
    "for d in tqdm(dat):\n",
    "    try:\n",
    "        item = d['scenario']['kb']['column_names']\n",
    "        [doc_colnames.append(t)  for t in item]\n",
    "    except TypeError:\n",
    "        continue\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns=list(set(doc_colnames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary for the databases\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "tokenizer=Tokenizer(filters=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(doc_kb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts([\"<SOS>\",\"<EOS>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_VOCAB_LEN = len(tokenizer.word_index)+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Also fitting in all the conversations and other things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_dict(d):\n",
    "    texts=[]\n",
    "    texts.append(\" \".join(list(d.keys())))\n",
    "    for v in d.values():\n",
    "        if isinstance(v,str):\n",
    "            texts.append(v) \n",
    "        elif isinstance(v,list):\n",
    "            texts.append(\" \".join(all_texts(v)))\n",
    "        elif isinstance(v,dict):\n",
    "            texts.append(\" \".join(all_dict(v)))\n",
    "        else:\n",
    "            try:\n",
    "                texts.append(str(v))\n",
    "            except:\n",
    "                raise Exception(f'type of v is {type(v)}')\n",
    "    return texts\n",
    "\n",
    "def all_texts(data):\n",
    "    texts = []\n",
    "    for d in data:\n",
    "        if isinstance(d,dict):\n",
    "            texts.append(\" \".join(all_dict(d)))\n",
    "        elif isinstance(d,list):\n",
    "            texts.append(\" \".join(all_texts(d)))\n",
    "        elif isinstance(d,str):\n",
    "            texts.append(d)\n",
    "        else:\n",
    "            try:\n",
    "                texts.append(str(d))\n",
    "            except:\n",
    "                raise Exception(f'type of d is {type(d)}')\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(all_texts(valid_dat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(all_texts(dat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(all_texts(test_dat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "625"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['ok']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the db model first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns_wi={a:i for i,a in enumerate(all_columns)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all_columns\n",
    "assert tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_QUERIES = 1\n",
    "NUM_COL = len(all_columns)\n",
    "CONV_VOCAB_LEN = len(tokenizer.word_index)+1\n",
    "THRESHOLD = 0.5\n",
    "MAX_DB_RESULTS = 5\n",
    "MAX_ENTITY_LENGTH = 10\n",
    "OPERATOR_LEN = 6\n",
    "NUM_INTENTS = 3\n",
    "EMBEDDING_SIZE=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.zeros((5,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting rules based db to desired output first\n",
    "def results_to_vector(bs_output,pred_intent,operation,kb_data,kb_intent):\n",
    "    assert bs_output.shape == (NUM_COL,MAX_ENTITY_LENGTH,CONV_VOCAB_LEN)\n",
    "    assert operation.shape == (NUM_COL,OPERATOR_LEN)\n",
    "    pred_intent = np.argmax(pred_intent) if max(pred_intent)>THRESHOLD else None\n",
    "    kb_intent = np.argmax(kb_intent)\n",
    "    output=np.zeros((MAX_DB_RESULTS,NUM_COL,MAX_ENTITY_LENGTH,CONV_VOCAB_LEN))\n",
    "    if intent is None:\n",
    "        return output\n",
    "    q=bs_output\n",
    "    op = operation\n",
    "    op_conf =  np.max(op,axis=-1)\n",
    "    op_classes = np.argmax(op,axis=-1) \n",
    "    op_classes = [_q if _q_conf>THRESHOLD else None for _q,_q_conf in zip(op_classes,op_conf)]\n",
    "\n",
    "    q_ents = np.argmax(q,axis=-1)\n",
    "    q_confs = np.max(q,axis=-1)\n",
    "    q_mask = np.array(q_confs>THRESHOLD,dtype='float32')\n",
    "    q_ents = q_mask*q_ents\n",
    "    q_words = [\" \".join([tokenizer.index_word[_q] for _q in __q if _q!=0]) for __q in q_ents]\n",
    "    # Now that q_words and op_classes are known\n",
    "    bs={}\n",
    "    operations = {}\n",
    "    for j,ent in enumerate(q_words):\n",
    "        if ent is None or ent==\"\": continue\n",
    "        bs[all_columns[j]]=ent\n",
    "        operations[all_columns[j]] = op_classes[j]\n",
    "    result,confidence = kb_results(kb_data,kb_intent,columns,pred_intent,bs,operations)\n",
    "    result=np.array(result)\n",
    "    confidence=np.array(confidence)\n",
    "    result = result[np.argsort(confidence)[-1::-1]]\n",
    "    confidence = confidence[np.argsort(confidence)[-1::-1]]\n",
    "    final_result=[kb_data[_i] for _i,(c,r) in enumerate(zip(confidence,result)) if c>=THRESHOLD and r==1]\n",
    "    confidence=[confidence[_i] for _i,(c,r) in enumerate(zip(confidence,result)) if c>=THRESHOLD and r==1]\n",
    "    kb_result = np.zeros((MAX_DB_RESULTS,NUM_COL,MAX_ENTITY_LENGTH,CONV_VOCAB_LEN))\n",
    "    for j,r in enumerate(final_result):\n",
    "        if j==MAX_DB_RESULTS: break\n",
    "        for k,v in r.items():\n",
    "            kb_result[j,all_columns_wi[k]] = to_categorical(pad_sequences(tokenizer.texts_to_sequences([v]),maxlen=MAX_ENTITY_LENGTH)\\\n",
    "                                                             ,num_classes=CONV_VOCAB_LEN)*confidence[j]\n",
    "\n",
    "    output = kb_result\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_output=np.zeros((NUM_COL,MAX_ENTITY_LENGTH,CONV_VOCAB_LEN))\n",
    "intent=np.array([1,0,0])\n",
    "operation = np.zeros((NUM_COL,OPERATOR_LEN))\n",
    "bs_output[19,0]=to_categorical(tokenizer.texts_to_sequences(['dish'])[0],num_classes=CONV_VOCAB_LEN)\n",
    "operation[19,0]=1.0\n",
    "kb_data = dat[0]['scenario']['kb']['items']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 20, 10, 6183)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_to_vector(bs_output,intent,operation,kb_data,kb_intent).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input,Dense,LSTM,Embedding,TimeDistributed, RepeatVector, Concatenate,Reshape\n",
    "from keras.layers import Lambda\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 1, 20, 50)\n"
     ]
    }
   ],
   "source": [
    "# model for db\n",
    "bs_input = Input(shape=(MAX_QUERIES,NUM_COL,MAX_ENTITY_LENGTH,CONV_VOCAB_LEN))\n",
    "intent_input = Input(shape=(MAX_QUERIES,NUM_INTENTS,))\n",
    "operation_input = Input(shape=(MAX_QUERIES,NUM_COL,OPERATOR_LEN))\n",
    "\n",
    "bs_proc = TimeDistributed(TimeDistributed(TimeDistributed(Dense(10,activation='sigmoid'))))(bs_input)\n",
    "LSTM_bs_emb = TimeDistributed(TimeDistributed(LSTM(50,return_sequences=False,return_state=False)))(bs_proc)\n",
    "rep_intent_input = TimeDistributed(RepeatVector(NUM_COL))(intent_input)\n",
    "print(LSTM_bs_emb.shape)\n",
    "all_steps = Concatenate(axis=-1)([LSTM_bs_emb,operation_input,rep_intent_input])\n",
    "all_steps = Lambda(lambda x: tf.reshape(x,shape=(-1,MAX_QUERIES,NUM_COL*(50+OPERATOR_LEN+NUM_INTENTS))))(all_steps)\n",
    "encoder_lstm = Dense(50,activation='relu')(all_steps)\n",
    "encoder_lstm = TimeDistributed(RepeatVector(MAX_DB_RESULTS))(encoder_lstm)\n",
    "\n",
    "decoder_lstm1 = TimeDistributed(LSTM(50,return_sequences=True))(encoder_lstm)\n",
    "\n",
    "decoder_lstm1 = Dense(NUM_COL*50,activation='relu')(decoder_lstm1)\n",
    "decoder_lstm1 = Lambda(lambda x: tf.reshape(x,shape=(-1,MAX_QUERIES,MAX_DB_RESULTS,NUM_COL,50)))(decoder_lstm1)\n",
    "\n",
    "\n",
    "decoder_lstm2 = TimeDistributed(Lambda(lambda x: K.tile(K.expand_dims(x,axis=-2),[1,1,1,MAX_ENTITY_LENGTH,1])))(decoder_lstm1)\n",
    "decoder_lstm3 = TimeDistributed(TimeDistributed(TimeDistributed(LSTM(10,return_sequences=True))))(decoder_lstm2)\n",
    "\n",
    "out = TimeDistributed(TimeDistributed(TimeDistributed(TimeDistributed(Dense(CONV_VOCAB_LEN,activation='softmax')))))(decoder_lstm3)\n",
    "db_model = Model(inputs=[bs_input,intent_input,operation_input],outputs=[out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 1, 20, 10, 61 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistrib (None, 1, 20, 10, 10 61840       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 1, 3)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_5 (TimeDistrib (None, 1, 20, 50)    12200       time_distributed_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 1, 20, 6)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_6 (TimeDistrib (None, 1, 20, 3)     0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1, 20, 59)    0           time_distributed_5[0][0]         \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 time_distributed_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1, 1180)      0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1, 50)        59050       lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_7 (TimeDistrib (None, 1, 5, 50)     0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_8 (TimeDistrib (None, 1, 5, 50)     20200       time_distributed_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1, 5, 1000)   51000       time_distributed_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 1, 5, 20, 50) 0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_9 (TimeDistrib (None, 1, 5, 20, 10, 0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_12 (TimeDistri (None, 1, 5, 20, 10, 2440        time_distributed_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_16 (TimeDistri (None, 1, 5, 20, 10, 68013       time_distributed_12[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 274,743\n",
      "Trainable params: 274,743\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "db_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_model.compile(optimizer='adam',loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing training inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(w, t = 1.0):\n",
    "    e = np.exp(np.array(w) / t)\n",
    "    dist = e / np.sum(e)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "intents = ['schedule', 'weather', 'navigate']\n",
    "def input_generator(batch_size,data=dat):\n",
    "    batch_data1=[]\n",
    "    batch_data2=[]\n",
    "    batch_data3=[]\n",
    "    target=[]\n",
    "    random_dat = [data[i] for i in np.random.permutation(len(data))]\n",
    "    ij=0\n",
    "    while True:\n",
    "        ij+=1\n",
    "        for d in random_dat:\n",
    "            kb_intent = d['scenario']['task']['intent']\n",
    "            kb_col_names = d['scenario']['kb']['column_names']\n",
    "            kb_data = d['scenario']['kb']['items']\n",
    "            true_vec_intent = np.zeros(NUM_INTENTS)\n",
    "            true_vec_intent[intents.index(kb_intent)]=1.0\n",
    "            pred_intent = softmax(np.random.normal(size=NUM_INTENTS,loc=100,scale=5))\n",
    "            bs_input = np.zeros((NUM_COL,MAX_ENTITY_LENGTH,CONV_VOCAB_LEN))\n",
    "            operation = np.zeros((NUM_COL,OPERATOR_LEN))\n",
    "            num_cols_to_have = np.random.randint(NUM_COL)\n",
    "            num_ents_to_have = [np.random.randint(NUM_COL) for _ in range(num_cols_to_have)]\n",
    "            for ii in range(num_cols_to_have):\n",
    "                for j in range(num_ents_to_have[ii]):\n",
    "                    ix=(np.random.randint(NUM_COL),np.random.randint(MAX_ENTITY_LENGTH))\n",
    "                    bs_input[ix] = softmax(np.random.normal(size=CONV_VOCAB_LEN,loc=100,scale=5))\n",
    "                operation[np.random.randint(NUM_COL)] = softmax(np.random.normal(size=OPERATOR_LEN,loc=100,scale=5))\n",
    "            batch_data1.append([bs_input])\n",
    "            batch_data2.append([operation])\n",
    "            batch_data3.append([pred_intent])\n",
    "            target.append([results_to_vector(bs_input,pred_intent,operation,kb_data,true_vec_intent)])\n",
    "            \n",
    "            if len(batch_data1)==batch_size:\n",
    "                yield [np.array(batch_data1),np.array(batch_data3),np.array(batch_data2)],np.array(target)\n",
    "                batch_data1=[]\n",
    "                batch_data2=[]\n",
    "                batch_data3=[]\n",
    "                target=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1=next(input_generator(1,dat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "def memory_exhausted():\n",
    "    if memory_percent_available()<=10:\n",
    "        print(\"Memory Exhausted\")\n",
    "        exit()\n",
    "class memCall(keras.callbacks.Callback):\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        memory_exhausted()\n",
    "        \n",
    "def memory_percent_available():\n",
    "    return psutil.virtual_memory().available/psutil.virtual_memory().total*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint=keras.callbacks.ModelCheckpoint('./db_model.h5',save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "batch_size=1\n",
    "db_model.fit_generator(input_generator(batch_size),validation_data=input_generator(batch_size,valid_dat),steps_per_epoch=1250,epochs=10,validation_steps=10000,callbacks=[memCall(),checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing db_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_model.load_weights('db_model_colab.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03056308627128601"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size=1\n",
    "db_model.evaluate_generator(input_generator(batch_size,valid_dat),steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "kb_data = dat[22]['scenario']['kb']['items']\n",
    "kb_intent = dat[22]['scenario']['task']['intent']\n",
    "columns = dat[22]['scenario']['kb']['column_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_kb_intent = kb_intent\n",
    "belief_state = {'traffic_info':'no traffic','distance':'6 miles'}\n",
    "operation = {'traffic_info':0,'distance':2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'traffic_info': 'no traffic', 'distance': '6 miles'}"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "belief_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " array([1.        , 1.        , 1.        , 0.69230769, 0.69565217,\n",
       "        0.69565217, 1.        , 1.        ]))"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kb_results(kb_data,kb_intent,columns,pred_kb_intent,belief_state,operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[65, 20]]"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences(['no traffic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'location': 0,\n",
       " 'thursday': 1,\n",
       " 'traffic_info': 2,\n",
       " 'address': 3,\n",
       " 'room': 4,\n",
       " 'party': 5,\n",
       " 'wednesday': 6,\n",
       " 'saturday': 7,\n",
       " 'sunday': 8,\n",
       " 'today': 9,\n",
       " 'friday': 10,\n",
       " 'event': 11,\n",
       " 'time': 12,\n",
       " 'distance': 13,\n",
       " 'date': 14,\n",
       " 'poi': 15,\n",
       " 'monday': 16,\n",
       " 'tuesday': 17,\n",
       " 'poi_type': 18,\n",
       " 'agenda': 19}"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_columns_wi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_output=np.zeros((NUM_COL,MAX_ENTITY_LENGTH,CONV_VOCAB_LEN))\n",
    "intent=np.array([0,0,1])\n",
    "operation = np.zeros((NUM_COL,OPERATOR_LEN))\n",
    "bs_output[13,0:2]=to_categorical(tokenizer.texts_to_sequences(['6 miles'])[0],num_classes=CONV_VOCAB_LEN)\n",
    "operation[13] = np.array([1,0,0,0,0,0])\n",
    "kb_data = dat[0]['scenario']['kb']['items']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "act=results_to_vector(bs_output,intent,operation,kb_data,intent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=db_model.predict([np.array([[bs_output]]),np.array([[intent]]),np.array([[operation]])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 5, 20, 10, 6183)"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       " array([[0.23864628, 0.5206451 , 0.5605651 , 0.5658833 , 0.5666025 ,\n",
       "         0.56670004, 0.5667132 , 0.5667149 , 0.5667153 , 0.56671524],\n",
       "        [0.23871124, 0.5206845 , 0.56057453, 0.56588525, 0.56660295,\n",
       "         0.5667    , 0.5667132 , 0.5667149 , 0.5667153 , 0.56671524],\n",
       "        [0.23902477, 0.52078056, 0.5605924 , 0.5658881 , 0.5666034 ,\n",
       "         0.5667002 , 0.5667132 , 0.5667149 , 0.5667153 , 0.56671524],\n",
       "        [0.23879276, 0.5207056 , 0.5605777 , 0.56588566, 0.56660295,\n",
       "         0.5667002 , 0.5667132 , 0.5667149 , 0.5667153 , 0.56671524],\n",
       "        [0.23906401, 0.52079   , 0.5605938 , 0.5658886 , 0.5666034 ,\n",
       "         0.5667002 , 0.5667132 , 0.5667149 , 0.5667153 , 0.56671524],\n",
       "        [0.23912981, 0.5208094 , 0.56059736, 0.5658893 , 0.56660336,\n",
       "         0.5667002 , 0.5667132 , 0.5667149 , 0.5667153 , 0.56671524],\n",
       "        [0.23911731, 0.5208071 , 0.5605972 , 0.5658893 , 0.56660366,\n",
       "         0.5667002 , 0.5667132 , 0.5667149 , 0.5667153 , 0.56671524],\n",
       "        [0.23882563, 0.52070916, 0.56057787, 0.5658859 , 0.56660295,\n",
       "         0.5667    , 0.5667132 , 0.5667149 , 0.5667153 , 0.56671524],\n",
       "        [0.2389296 , 0.52073866, 0.5605833 , 0.56588674, 0.56660324,\n",
       "         0.5667002 , 0.5667132 , 0.5667149 , 0.5667153 , 0.56671524],\n",
       "        [0.23903957, 0.5207817 , 0.56059235, 0.5658884 , 0.56660336,\n",
       "         0.5667002 , 0.5667132 , 0.5667149 , 0.5667153 , 0.56671524],\n",
       "        [0.23899332, 0.52076656, 0.5605895 , 0.565888  , 0.5666032 ,\n",
       "         0.5667002 , 0.5667132 , 0.5667149 , 0.5667153 , 0.56671524],\n",
       "        [0.23896094, 0.52076155, 0.56058896, 0.5658878 , 0.56660324,\n",
       "         0.5667002 , 0.5667132 , 0.5667149 , 0.5667153 , 0.56671524],\n",
       "        [0.23889531, 0.5207428 , 0.56058544, 0.56588715, 0.56660324,\n",
       "         0.5667002 , 0.5667132 , 0.5667149 , 0.5667153 , 0.56671524],\n",
       "        [0.23900723, 0.52078104, 0.5605929 , 0.5658887 , 0.5666034 ,\n",
       "         0.5667002 , 0.5667132 , 0.5667149 , 0.5667153 , 0.56671524],\n",
       "        [0.23900697, 0.5207729 , 0.56059057, 0.5658881 , 0.5666034 ,\n",
       "         0.5667002 , 0.5667132 , 0.5667149 , 0.5667153 , 0.56671524],\n",
       "        [0.23894095, 0.5207451 , 0.5605831 , 0.56588477, 0.5666023 ,\n",
       "         0.5667001 , 0.56671315, 0.5667149 , 0.5667153 , 0.56671524],\n",
       "        [0.23903635, 0.5207833 , 0.5605927 , 0.5658886 , 0.5666034 ,\n",
       "         0.5667002 , 0.5667132 , 0.5667149 , 0.5667153 , 0.56671524],\n",
       "        [0.23895636, 0.5207631 , 0.56058973, 0.565888  , 0.5666034 ,\n",
       "         0.5667002 , 0.5667132 , 0.5667149 , 0.5667153 , 0.56671524],\n",
       "        [0.23871626, 0.5206915 , 0.56057614, 0.5658857 , 0.56660295,\n",
       "         0.5667    , 0.5667132 , 0.5667149 , 0.5667153 , 0.56671524],\n",
       "        [0.23907456, 0.52079344, 0.5605947 , 0.5658889 , 0.56660336,\n",
       "         0.5667002 , 0.5667132 , 0.5667149 , 0.5667153 , 0.56671524]],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(pred[0][0][0],axis=-1),np.max(pred[0][0][0],axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 130, 131,  76],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 334, 153,  68],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  89,  12],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 305, 111],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 111, 104],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(act[0],axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1=next(input_generator(1,dat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0.0)"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(a1[0][0][0][0][0][-1]),np.max(a1[0][0][0][0][0][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pympler import muppy\n",
    "from pympler import summary\n",
    "all_objects = muppy.get_objects()\n",
    "sum1 = summary.summarize(all_objects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_memory_usage(batch_size, model):\n",
    "    import numpy as np\n",
    "    from keras import backend as K\n",
    "\n",
    "    shapes_mem_count = 0\n",
    "    for l in model.layers:\n",
    "        single_layer_mem = 1\n",
    "        for s in l.output_shape:\n",
    "            if s is None:\n",
    "                continue\n",
    "            single_layer_mem *= s\n",
    "        shapes_mem_count += single_layer_mem\n",
    "\n",
    "    trainable_count = np.sum([K.count_params(p) for p in set(model.trainable_weights)])\n",
    "    non_trainable_count = np.sum([K.count_params(p) for p in set(model.non_trainable_weights)])\n",
    "\n",
    "    total_memory = 4.0*batch_size*(shapes_mem_count + trainable_count + non_trainable_count)\n",
    "    gbytes = np.round(total_memory / (1024.0 ** 3), 3)\n",
    "    return gbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.463"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_model_memory_usage(16,db_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pympler import asizeof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56.60871887207031"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asizeof.asizeof(a1)/1024/1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'LazyConfigValue' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-a73f7f1b2bdb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0masizeof\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masizeof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pympler/asizeof.py\u001b[0m in \u001b[0;36masizeof\u001b[0;34m(*objs, **opts)\u001b[0m\n\u001b[1;32m   2186\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2187\u001b[0m         \u001b[0m_asizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2188\u001b[0;31m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masizeof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2189\u001b[0m         \u001b[0m_asizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# show opts as _kwdstr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2190\u001b[0m         \u001b[0m_asizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pympler/asizeof.py\u001b[0m in \u001b[0;36masizeof\u001b[0;34m(self, *objs, **opts)\u001b[0m\n\u001b[1;32m   1778\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1779\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1780\u001b[0;31m         \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sizes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1781\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pympler/asizeof.py\u001b[0m in \u001b[0;36m_sizes\u001b[0;34m(self, objs, sized)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_duplicate\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1750\u001b[0;31m                 \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m             \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msized\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pympler/asizeof.py\u001b[0m in \u001b[0;36m_sizer\u001b[0;34m(self, obj, deep, sized)\u001b[0m\n\u001b[1;32m   1724\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# no sum(<generator_expression>) in Python 2.2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1725\u001b[0m                             \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1726\u001b[0;31m                                 \u001b[0ms\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1727\u001b[0m                          \u001b[0;31m# recursion depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1728\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_depth\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pympler/asizeof.py\u001b[0m in \u001b[0;36m_sizer\u001b[0;34m(self, obj, deep, sized)\u001b[0m\n\u001b[1;32m   1724\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# no sum(<generator_expression>) in Python 2.2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1725\u001b[0m                             \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1726\u001b[0;31m                                 \u001b[0ms\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1727\u001b[0m                          \u001b[0;31m# recursion depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1728\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_depth\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pympler/asizeof.py\u001b[0m in \u001b[0;36m_sizer\u001b[0;34m(self, obj, deep, sized)\u001b[0m\n\u001b[1;32m   1724\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# no sum(<generator_expression>) in Python 2.2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1725\u001b[0m                             \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1726\u001b[0;31m                                 \u001b[0ms\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1727\u001b[0m                          \u001b[0;31m# recursion depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1728\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_depth\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pympler/asizeof.py\u001b[0m in \u001b[0;36m_sizer\u001b[0;34m(self, obj, deep, sized)\u001b[0m\n\u001b[1;32m   1724\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# no sum(<generator_expression>) in Python 2.2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1725\u001b[0m                             \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1726\u001b[0;31m                                 \u001b[0ms\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1727\u001b[0m                          \u001b[0;31m# recursion depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1728\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_depth\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pympler/asizeof.py\u001b[0m in \u001b[0;36m_sizer\u001b[0;34m(self, obj, deep, sized)\u001b[0m\n\u001b[1;32m   1724\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# no sum(<generator_expression>) in Python 2.2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1725\u001b[0m                             \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1726\u001b[0;31m                                 \u001b[0ms\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1727\u001b[0m                          \u001b[0;31m# recursion depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1728\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_depth\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pympler/asizeof.py\u001b[0m in \u001b[0;36m_sizer\u001b[0;34m(self, obj, deep, sized)\u001b[0m\n\u001b[1;32m   1724\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# no sum(<generator_expression>) in Python 2.2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1725\u001b[0m                             \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1726\u001b[0;31m                                 \u001b[0ms\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1727\u001b[0m                          \u001b[0;31m# recursion depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1728\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_depth\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pympler/asizeof.py\u001b[0m in \u001b[0;36m_sizer\u001b[0;34m(self, obj, deep, sized)\u001b[0m\n\u001b[1;32m   1724\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# no sum(<generator_expression>) in Python 2.2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1725\u001b[0m                             \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1726\u001b[0;31m                                 \u001b[0ms\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1727\u001b[0m                          \u001b[0;31m# recursion depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1728\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_depth\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pympler/asizeof.py\u001b[0m in \u001b[0;36m_sizer\u001b[0;34m(self, obj, deep, sized)\u001b[0m\n\u001b[1;32m   1724\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# no sum(<generator_expression>) in Python 2.2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1725\u001b[0m                             \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1726\u001b[0;31m                                 \u001b[0ms\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1727\u001b[0m                          \u001b[0;31m# recursion depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1728\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_depth\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pympler/asizeof.py\u001b[0m in \u001b[0;36m_sizer\u001b[0;34m(self, obj, deep, sized)\u001b[0m\n\u001b[1;32m   1724\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# no sum(<generator_expression>) in Python 2.2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1725\u001b[0m                             \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1726\u001b[0;31m                                 \u001b[0ms\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1727\u001b[0m                          \u001b[0;31m# recursion depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1728\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_depth\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pympler/asizeof.py\u001b[0m in \u001b[0;36m_sizer\u001b[0;34m(self, obj, deep, sized)\u001b[0m\n\u001b[1;32m   1724\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# no sum(<generator_expression>) in Python 2.2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1725\u001b[0m                             \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1726\u001b[0;31m                                 \u001b[0ms\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1727\u001b[0m                          \u001b[0;31m# recursion depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1728\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_depth\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pympler/asizeof.py\u001b[0m in \u001b[0;36m_sizer\u001b[0;34m(self, obj, deep, sized)\u001b[0m\n\u001b[1;32m   1724\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# no sum(<generator_expression>) in Python 2.2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1725\u001b[0m                             \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1726\u001b[0;31m                                 \u001b[0ms\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1727\u001b[0m                          \u001b[0;31m# recursion depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1728\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_depth\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pympler/asizeof.py\u001b[0m in \u001b[0;36m_sizer\u001b[0;34m(self, obj, deep, sized)\u001b[0m\n\u001b[1;32m   1724\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# no sum(<generator_expression>) in Python 2.2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1725\u001b[0m                             \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1726\u001b[0;31m                                 \u001b[0ms\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1727\u001b[0m                          \u001b[0;31m# recursion depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1728\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_depth\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pympler/asizeof.py\u001b[0m in \u001b[0;36m_sizer\u001b[0;34m(self, obj, deep, sized)\u001b[0m\n\u001b[1;32m   1724\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# no sum(<generator_expression>) in Python 2.2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1725\u001b[0m                             \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1726\u001b[0;31m                                 \u001b[0ms\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1727\u001b[0m                          \u001b[0;31m# recursion depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1728\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_depth\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pympler/asizeof.py\u001b[0m in \u001b[0;36m_sizer\u001b[0;34m(self, obj, deep, sized)\u001b[0m\n\u001b[1;32m   1724\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# no sum(<generator_expression>) in Python 2.2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1725\u001b[0m                             \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1726\u001b[0;31m                                 \u001b[0ms\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1727\u001b[0m                          \u001b[0;31m# recursion depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1728\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_depth\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pympler/asizeof.py\u001b[0m in \u001b[0;36m_sizer\u001b[0;34m(self, obj, deep, sized)\u001b[0m\n\u001b[1;32m   1724\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# no sum(<generator_expression>) in Python 2.2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1725\u001b[0m                             \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1726\u001b[0;31m                                 \u001b[0ms\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1727\u001b[0m                          \u001b[0;31m# recursion depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1728\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_depth\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pympler/asizeof.py\u001b[0m in \u001b[0;36m_sizer\u001b[0;34m(self, obj, deep, sized)\u001b[0m\n\u001b[1;32m   1724\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# no sum(<generator_expression>) in Python 2.2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1725\u001b[0m                             \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1726\u001b[0;31m                                 \u001b[0ms\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1727\u001b[0m                          \u001b[0;31m# recursion depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1728\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_depth\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pympler/asizeof.py\u001b[0m in \u001b[0;36m_sizer\u001b[0;34m(self, obj, deep, sized)\u001b[0m\n\u001b[1;32m   1724\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# no sum(<generator_expression>) in Python 2.2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1725\u001b[0m                             \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1726\u001b[0;31m                                 \u001b[0ms\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1727\u001b[0m                          \u001b[0;31m# recursion depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1728\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_depth\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pympler/asizeof.py\u001b[0m in \u001b[0;36m_sizer\u001b[0;34m(self, obj, deep, sized)\u001b[0m\n\u001b[1;32m   1724\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# no sum(<generator_expression>) in Python 2.2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1725\u001b[0m                             \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1726\u001b[0;31m                                 \u001b[0ms\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1727\u001b[0m                          \u001b[0;31m# recursion depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1728\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_depth\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pympler/asizeof.py\u001b[0m in \u001b[0;36m_sizer\u001b[0;34m(self, obj, deep, sized)\u001b[0m\n\u001b[1;32m   1724\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# no sum(<generator_expression>) in Python 2.2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1725\u001b[0m                             \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1726\u001b[0;31m                                 \u001b[0ms\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1727\u001b[0m                          \u001b[0;31m# recursion depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1728\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_depth\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pympler/asizeof.py\u001b[0m in \u001b[0;36m_sizer\u001b[0;34m(self, obj, deep, sized)\u001b[0m\n\u001b[1;32m   1724\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# no sum(<generator_expression>) in Python 2.2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1725\u001b[0m                             \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1726\u001b[0;31m                                 \u001b[0ms\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1727\u001b[0m                          \u001b[0;31m# recursion depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1728\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_depth\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pympler/asizeof.py\u001b[0m in \u001b[0;36m_sizer\u001b[0;34m(self, obj, deep, sized)\u001b[0m\n\u001b[1;32m   1723\u001b[0m                                 \u001b[0ms\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1724\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# no sum(<generator_expression>) in Python 2.2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1725\u001b[0;31m                             \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1726\u001b[0m                                 \u001b[0ms\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1727\u001b[0m                          \u001b[0;31m# recursion depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pympler/asizeof.py\u001b[0m in \u001b[0;36m_dict_refs\u001b[0;34m(obj, named)\u001b[0m\n\u001b[1;32m    590\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_items\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pympler/asizeof.py\u001b[0m in \u001b[0;36m_items\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    254\u001b[0m     '''Return iter-/generator, preferably.\n\u001b[1;32m    255\u001b[0m     '''\n\u001b[0;32m--> 256\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'iteritems'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'LazyConfigValue' object is not callable"
     ]
    }
   ],
   "source": [
    "asizeof.asizeof(db_model.layers[0])/1024/1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the complete model now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model would receive the belief states and give out the sentences in the coeherent form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 30\n",
    "LATENT_DIM = 50\n",
    "CONV_VOCAB_LEN = 30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.engine.network import Network\n",
    "def get_model(db_m):\n",
    "    frozen_db_m = Network(db_m.input,db_m.output,name='frozen_db_model')\n",
    "    \n",
    "    text_in = Input(shape=(MAX_SEQ_LEN,EMBEDDING_SIZE))\n",
    "    text_tok_in = Input(shape=(MAX_SEQ_LEN,CONV_VOCAB_LEN))\n",
    "    emb_state_in_h = Input(shape=(LATENT_DIM,))\n",
    "    emb_state_in_c = Input(shape=(LATENT_DIM,))\n",
    "    \n",
    "    encoding,emb_state_out_h,emb_state_out_c = LSTM(LATENT_DIM,\\\n",
    "                                                    return_state=True)(text_in,\\\n",
    "                                            initial_state=[emb_state_in_h,emb_state_in_c])\n",
    "    \n",
    "    \n",
    "    \n",
    "    db_decoder_1 = Lambda(lambda x: K.tile(K.expand_dims(x,axis=-2),[1,MAX_QUERIES,1]))(encoding)\n",
    "    db_decoder_2 = LSTM(NUM_COL*LATENT_DIM,return_sequences=True)(db_decoder_1)\n",
    "    db_decoder_2 = Lambda(lambda x: tf.reshape(x,[-1,MAX_QUERIES,NUM_COL,LATENT_DIM]))(db_decoder_2)\n",
    "    \n",
    "    db_decoder_3 = Lambda(lambda x: K.tile(K.expand_dims(x,axis=-2),[1,1,1,MAX_ENTITY_LENGTH,1]))(db_decoder_2)\n",
    "    db = TimeDistributed(TimeDistributed(LSTM(LATENT_DIM,return_sequences=True)))(db_decoder_3)\n",
    "    bs_out = Dense(MAX_SEQ_LEN,activation='softmax')(db)\n",
    "    text_tok_in_reshape = Lambda(lambda x: tf.reshape(x,[-1,1,1,1,MAX_SEQ_LEN,CONV_VOCAB_LEN]))(text_tok_in)\n",
    "    \n",
    "    bs_out = Lambda(lambda x: K.expand_dims(x))(bs_out)\n",
    "    print(bs_out.shape,text_tok_in_reshape.shape)\n",
    "    bs_out = Lambda(lambda x: tf.reduce_sum(x[0]*x[1],axis=-2))([bs_out,text_tok_in])\n",
    "    print(bs_out.shape)\n",
    "    op_out = Dense(LATENT_DIM,activation='relu')(db_decoder_2)\n",
    "    op_out = Dense(OPERATOR_LEN,activation='softmax')(op_out)\n",
    "    print(op_out.shape)\n",
    "    intent_out = Dense(LATENT_DIM,activation='relu')(encoding)\n",
    "    intent_out = Dense(NUM_INTENTS,activation='softmax')(intent_out)\n",
    "    intent_out = RepeatVector(MAX_QUERIES)(intent_out)\n",
    "    model_bs = Model(inputs=[text_in,emb_state_in_h,emb_state_in_c,text_tok_in],outputs=[bs_out,intent_out,op_out])\n",
    "    # DECODER\n",
    "    print(bs_out,intent_out,op_out)\n",
    "    decoder_input_db = frozen_db_m([bs_out,intent_out,op_out])\n",
    "    other_bs_input = encoding\n",
    "    \n",
    "    #Mdecoder_input_b is of length None,MAX_QUERIES,MAX_DB_RESULTS,NUM_COL,MAX_ENTITY_LENGTH,CONV_VOCAB_LEN\n",
    "    dbout_encoder_maxent = TimeDistributed(TimeDistributed(TimeDistributed(LSTM(LATENT_DIM))))(decoder_input_db)\n",
    "    dbout_encoder_ncol =  Lambda(lambda x: tf.reshape(x,[-1,MAX_QUERIES,MAX_DB_RESULTS,NUM_COL*LATENT_DIM]))(dbout_encoder_maxent)\n",
    "    dbout_encoder_ncol = Dense(LATENT_DIM,activation='relu')(dbout_encoder_ncol)\n",
    "    dbout_encoder_dbr = TimeDistributed(LSTM(LATENT_DIM))(dbout_encoder_ncol)\n",
    "    other_bs_input_rep = RepeatVector(MAX_QUERIES)(other_bs_input)\n",
    "    dbout_encoder = Concatenate(axis=-1)([dbout_encoder_dbr,other_bs_input_rep])\n",
    "    _,dbout_s,dbout_h = LSTM(LATENT_DIM,return_state=True)(dbout_encoder)\n",
    "    decoder_hidden_inputs = [dbout_s,dbout_h]\n",
    "    \n",
    "    decoder_inputs = Input(shape=(MAX_SEQ_LEN,EMBEDDING_SIZE))\n",
    "    print(decoder_inputs.shape,decoder_hidden_inputs[0].shape,decoder_hidden_inputs[1].shape)\n",
    "    decoder_LSTM = LSTM(LATENT_DIM,return_sequences=True,return_state=True)\n",
    "    decoder_outputs,_,_ = decoder_LSTM(decoder_inputs,initial_state=decoder_hidden_inputs)\n",
    "    decoder_outputs = Dense(CONV_VOCAB_LEN,activation='softmax')(decoder_outputs)\n",
    "    \n",
    "    full_model = Model(inputs=[text_in,emb_state_in_h,emb_state_in_c,text_tok_in,decoder_inputs],outputs=[decoder_outputs])\n",
    "    full_model.compile(loss='categorical_crossentropy',optimizer='adam')\n",
    "    return full_model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model=get_model(db_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input((10,vocab_len))\n",
    "encoder = LSTM(50,return_state=True)\n",
    "out,out_h,out_c=encoder(inp)\n",
    "out = Dense(vocab_len,activation='softmax')(out)\n",
    "model_rnn_2=Model(inputs=[inp],outputs=out)\n",
    "\n",
    "out_3 = frozen_db_model(model_rnn_2.output)\n",
    "out_35 = RepeatVector(10)(out_3)\n",
    "decoder = LSTM(50,return_sequences=True,return_state=True)\n",
    "out_4,_,_= decoder(out_35,initial_state=[out_h,out_c])\n",
    "out_4 = Dense(vocab_len,activation='softmax')(out_4)\n",
    "model_4 = Model(inputs=[model_rnn_2.input],outputs=[model_rnn_2.output,out_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
